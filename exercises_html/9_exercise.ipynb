{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 9: Double machine learning\n",
    "\n",
    "In this exercise set we will once again be working with estimation of conditional average treatment effects assuming selection on observables. However, this time the focus will be more broadly on double machine learning in `econml`, learning how to utilize these methods to get estimates, both assuming a partially linear model (`LinearDML`) and non-parametrically using causal forests (`CausalForestDML`).\n",
    "\n",
    "As an example we will examine the age-old question of orange juice price-elasticity, which, as we all know, have haunted economists for millenia. To answer this question we will use a subset of [Dominick's dataset](\n",
    "https://www.chicagobooth.edu/research/kilts/datasets/dominicks) from the James M. Kilts Center, University of Chicago Booth School of Business. The data is a repeated cross sectional from stores (which we pool), where our main variables of interest are the amount of units sold (outcome) and the price of orange juice (treatment) and median income in the neighborhood (treatment effect heterogeneity). A description of the dataset can be seen [here](https://rdrr.io/cran/bayesm/man/orangeJuice.html). Throughout, we assume selection on observables. This exercise was in part inspired by the `econml` notebooks on causal model selection and double machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "## Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seed and plot style\n",
    "np.random.seed(73)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "In this first part of the exercise we will be digging straight into estimating treatment effects using double machine learning. As such, we will be postponing training of models for predicting `Y` and `T` for just a moment, although this is an essential part of double machine learning and should not be neglected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.1**\n",
    ">\n",
    "> Load the data using the following code and verify that you have correctly loaded the `DataFrame` by printing the first 5 rows.\n",
    ">\n",
    "> NOTE: The following code will download the file which might take a few seconds dependent on your internet.\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> `DataFrame`'s have a method called .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "file_name = \"oj_large.csv\"\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "    print(\"Download file\")\n",
    "    urllib.request.urlretrieve(\"https://msalicedatapublic.blob.core.windows.net/datasets/OrangeJuice/oj_large.csv\", file_name)\n",
    "    \n",
    "oj_data = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.2**\n",
    ">\n",
    "> The following code subsets the data into different parts corresponding to `X`, `Y`, `W` and `T`, but have been named temporary names. Which is which, and why?\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> What's just confounders and what drives heterogeneity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "non_categorical_cols = ['feat', 'AGE60', 'EDUC', 'ETHNIC', 'HHLARGE', 'WORKWOM', 'HVAL150', 'SSTRDIST', 'SSTRVOL', 'CPDIST5', 'CPWVOL5']\n",
    "categorical_cols = ['brand']\n",
    "\n",
    "temp_1 = scaler.fit_transform(oj_data[non_categorical_cols].values)\n",
    "temp_2 = scaler.fit_transform(pd.get_dummies(oj_data[categorical_cols]).values)\n",
    "# Stacks categorical and non categorical variables together\n",
    "temp_3 = np.hstack([temp_1, temp_2]) \n",
    "temp_4 = np.log(oj_data[\"price\"]).values\n",
    "temp_5 = oj_data['logmove'].values\n",
    "temp_6 = scaler.fit_transform(oj_data[['INCOME']].values)\n",
    "\n",
    "X = # FILL IN\n",
    "W = # FILL IN\n",
    "Y = # FILL IN\n",
    "T = # FILL IN\n",
    "\n",
    "XW = np.hstack([X, W])\n",
    "\n",
    "Y_train, Y_val, T_train, T_val, X_train, X_val, W_train, W_val, XW_train, XW_val = train_test_split(Y, T, X, W, XW, test_size=.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.3**\n",
    ">\n",
    "> Create an instance of a `LinearDML` and fit it to the training data using default input parameters. \n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> There's an example on [this page](https://econml.azurewebsites.net/spec/estimation/dml.html#when-should-you-use-it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.4**\n",
    ">\n",
    "> Look at the documentation for `LinearDML`, which can be found [here](https://econml.azurewebsites.net/_autosummary/econml.dml.LinearDML.html#econml.dml.LinearDML). \n",
    ">\n",
    "> How are the models for `Y` and `T` created? Does this explain why the data was scaled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.5**\n",
    ">\n",
    "> Get an estimate of the treatment effect heterogeneity using the `summary` method. Is the sign as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.6**\n",
    ">\n",
    "> Estimate and plot the conditional average treatment effect and the the 95\\% confidence interval with the `LinearDML` model on the following `X_test` data, which generates counterfactual income levels ranging from -1 to 1.\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> There documentation for `LinearDML` can be found on [this page](https://econml.azurewebsites.net/_autosummary/econml.dml.LinearDML.html#econml.dml.LinearDML). \n",
    ">>\n",
    ">> Try looking for methods that start with `effect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate test data\n",
    "min_income = -1\n",
    "max_income = 1\n",
    "delta = (1 - (-1)) / 100\n",
    "X_test = np.arange(min_income, max_income + delta - 0.001, delta).reshape(-1,1)\n",
    "\n",
    "# Calculate treatment effect and interval\n",
    "\n",
    "te_pred_linear = # FILL IN \n",
    "te_pred_interval_linear = # FILL IN \n",
    "\n",
    "# Plot Orange Juice elasticity as a function of income\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(X_test, te_pred_linear, label=\"Linear model\")\n",
    "plt.xlabel(r'Scale(Income)')\n",
    "plt.ylabel('Orange Juice Elasticity')\n",
    "plt.legend()\n",
    "plt.title(\"Orange Juice Elasticity vs Income\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.7**\n",
    ">\n",
    "> Create an instance of a `CausalForestDML` and fit it to the training data using default input parameters. \n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> It follows exactly the same recipe as `LinearDML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.8**\n",
    ">\n",
    "> Estimate and plot the conditional average treatment effect and the the 95\\% confidence interval with the `CausalForestDML` model `X_test`.\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> It follows exactly the same recipe as `LinearDML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed during the lecture, we can use the R-loss to evaluate the fit of the conditional average treatment effect and use this to perform causal model selection.\n",
    "\n",
    "This could be done manually, but much like `grf` in R, `econml` also offers automatic tuning with the `tune` method, which we will utilize to tune the causal forest in `CausalForestDML`.\n",
    "\n",
    "> **Exercise 1.9**\n",
    ">\n",
    "> Create an instance of a `CausalForestDML`, tune it on the training data and then fit it to the training data, all using default input parameters. \n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> The call to `tune` the model looks exactly like the call to `fit` the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.8**\n",
    ">\n",
    "> Estimate and plot the conditional average treatment effect and the the 95\\% confidence interval with the tuned `CausalForestDML` model on `X_test`.\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> It follows exactly the same recipe as `LinearDML` and an untuned `CausalForestDML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.9**\n",
    ">\n",
    "> Plot the conditional average treatment effect and the the 95\\% confidence interval for all three models on `X_test`. Which do your prefer?\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> You can call `plot` and `fill_between` repeatedly before calling `xlabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.10**\n",
    ">\n",
    "> `econml` implements a scoring function using the R-loss, called the `Rscorer`. Fit the `Rscorer` to the appropriate data sample.\n",
    ">\n",
    "> NOTE: The `Rscorer` needs a model to create residuals. Here we input a `LassoCV`, which is also the default in the double machine learning models. As such we obtain similar residuals.\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> Should we use training data or held out data for causal model selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.score import RScorer\n",
    "\n",
    "# Create scorer\n",
    "scorer = RScorer(model_y=LassoCV(), model_t=LassoCV())\n",
    "\n",
    "# FILL IN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.11**\n",
    ">\n",
    "> Score the models using the `Rscorer`'s `best_model` method. Which model is the preferred one? Is it preferred over a constant average treatment effect?\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> If you're in doubt as to which model the method has selected, you can return all the scores by setting `return_scores = True` and compare the best score to the list\n",
    ">>\n",
    ">> The `best_model` method accepts a list of fitted estimators, and the documentation can be seen [here](https://econml.azurewebsites.net/_autosummary/econml.score.RScorer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting treatment and outcome\n",
    "\n",
    "Having now looked closer at how to code up estimation of heterogeneous treatment effects using double machine learning estimators, we will start with the task that is predicting both `Y` and `T`, from which we can learn the optimal hyperparameters to pass on to our double machine learning estimators.\n",
    "\n",
    "In practice, this is probably where you will be spending most of the time, optimizing features and models to accurately predict treatment and outcome, thus achieving better converge rates.\n",
    "\n",
    "We have covered this in both session 3 and 4, where we covered model selection and supervised learning, respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.1**\n",
    ">\n",
    "> What covariates should we use to predict `Y` and `T`? Is this part of the train test split we made in exercise 1.1?\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> Look at the struqtural equations in the lecture slides. What enters in the nuisance functions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this go by slightly faster, I have pre-selected three models and their respective hyperparametergrids for which to search over. Furthermore, we utilize 2 fold cross validation (matching the default amount of folds in `econml`) and 10 random hyperparameter combinations using `RandomizedSearchCV`, which we covered in session 3. \n",
    "\n",
    "Each model should be using `negative_mean_squared_error`, and you should make note of the best performing hyper mean squared error, such that you can compare performance across estimators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.2**\n",
    ">\n",
    "> Create a `Lasso` to predict the outcome, `Y`.\n",
    ">\n",
    "> Save the best hyperparameter combination.\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> The best score and best hyperparameter can be found using the methods `best_score_` and `best_param_` respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn # FILL IN \n",
    "\n",
    "pipe_lasso = Pipeline([ \n",
    "    # FILL IN \n",
    "    ]\n",
    "    )\n",
    "\n",
    "param_grid = {'lasso__alpha':np.logspace(-5, 3, 10)}\n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    # FILL IN\n",
    ")\n",
    "\n",
    "# Fit\n",
    "# FILL IN\n",
    "\n",
    "# Score\n",
    "# FILL IN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.3**\n",
    ">\n",
    "> Create a `RandomForestRegressor` to predict the outcome, `Y`.\n",
    ">\n",
    "> Save the best hyperparameter combination.\n",
    ">\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> The best score and best hyperparameter can be found using the methods `best_score_` and `best_param_` respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn # FILL IN\n",
    "\n",
    "pipe_forest = Pipeline([                     \n",
    "    # FILL IN\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "param_grid= [{\n",
    "    'forest__n_estimators': np.unique(np.logspace(0, 3, 25).astype(int)),\n",
    "    'forest__max_features': np.arange(0.1, 1.01, 0.1),\n",
    "    'forest__min_samples_split': np.arange(0.01, 0.2, 0.01),\n",
    "    'forest__min_samples_leaf':  np.arange(2, 50, 2),\n",
    "    'forest__max_depth': np.unique(np.logspace(1, 4, 20).astype(int))\n",
    "    }]\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    # FILL IN\n",
    ")\n",
    "\n",
    "# Fit\n",
    "# FILL IN\n",
    "\n",
    "# Score\n",
    "# FILL IN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.4**\n",
    ">\n",
    "> Create a `HistGradientBoostingRegressor` to predict the outcome, `Y`. \n",
    ">\n",
    "> Save the best hyperparameter combination.\n",
    ">\n",
    "> NOTE: The `HistGradientBoostingRegressor` is an efficient model which does gradient boosting.\n",
    ">\n",
    ">>*Hints:*\n",
    ">> \n",
    ">> The best score and best hyperparameter can be found using the methods `best_score_` and `best_param_` respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "from sklearn # FILL IN\n",
    "\n",
    "pipe_booster = Pipeline([                     \n",
    "   # FILL IN\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "param_grid= [{\n",
    "    'booster__min_samples_leaf':  np.arange(2, 50, 2),\n",
    "    'booster__max_depth': np.unique(np.logspace(1, 4, 20).astype(int)),\n",
    "    'booster__learning_rate':np.arange(0,1.001,0.1)\n",
    "    }]\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    # FILL IN\n",
    ")\n",
    "\n",
    "# Fit\n",
    "# FILL IN\n",
    "\n",
    "# Score\n",
    "# FILL IN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.5**\n",
    ">\n",
    "> Which model best predicts `Y`? Create a model of that type with the best hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.6**\n",
    "> \n",
    "> You have now found the model which best predicts `Y`, and now we repeat the same process for `T`\n",
    "> \n",
    "> To find the best model to predict `T`, repeat exercise 2.2 through 2.5 but predicting `T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.7**\n",
    ">\n",
    "> Estimate a `LinearDML` as well as an untuned and tuned `CausalForestDML` using the new models for `T` and `Y`.\n",
    "> \n",
    "> Plot the conditional average treatment effect and the the 95\\% confidence interval for all three models on `X_test`. Which do your prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.8**\n",
    ">\n",
    "> Score the three new models using the `Rscorer`, now predicting the residuals using the models for `T` and `Y. Which model is the preferred one? Is it preferred over a constant average treatment effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing thoughts\n",
    "\n",
    "Today we have examined double machine learning and how to implement these models. \n",
    "\n",
    "In practice, you should spend more time creating the models for `T` and `Y`, as they are quintessential in double machine learning. You should also increase the amount of folds in cross validation, as this increases the amount of data to train on when creating residuals. Furthermore, both the models and `Rscorer` support monte carlo iterations, `mc_iters`, which allows you to repeat the same process again with different splits, thus creating less noisy estimates of the residuals. We have not done this today as the running time of these models quite quickly becomes too long for an exercise set.\n",
    "\n",
    "If you wish to examine linear treatment heterogeneity, you should also look into the input parameters `featurizer` and `treatment_featurizer`, which enables quick and easy interactions of covariates and treatments, possibly in combination with a `SparseLinearDML`. See e.g. [this notebook](https://github.com/microsoft/EconML/blob/main/notebooks/Treatment%20Featurization%20Examples.ipynb)\n",
    "\n",
    "All of the `econml` functionality that we went through last week can also still be used with our models, e.g. explainability, CATE interpreters and policy learning.\n",
    "\n",
    "Additionally, you should be aware that `econml` has a folder with notebook examples on their [GitHub](https://github.com/microsoft/EconML/tree/main/notebooks), where you can see the many different possibilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vive_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "50f1b660881291c5d31ad4d40c48915b3ef9364cc881d538585b11a7eb841304"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
