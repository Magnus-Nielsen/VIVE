[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine learning course for VIVE",
    "section": "",
    "text": "Session #\nTopic\nLecture\nExercises\nSolutions\nDocuments\n\n\n\n\n\n1\nIntroduktion til kurset og ML\nSlides\nSee slides\nN/A\nAnaconda guide\n\n\n\n2\nIndførsel til Python\nSlides\nNotebook / HTML\nNotebook / HTML\nReading\n\n\n\n3\nModel- og hyperparameterselektion\nSlides\nNotebook / HTML\nNotebook / HTML\nReading\n\n\n\n4\nSupervised ML\nSlides\nNotebook / HTML\n\nReading\n\n\n\n5\nUnsupervised ML\n\n\n\n\n\n\n\n6\nFortolkning af modeller\n\n\n\n\n\n\n\n7\nAlgorithmic audits\n\n\n\n\n\n\n\n8\nKausalitet – Træbaserede modeller\n\n\n\n\n\n\n\n9\nKausalitet - Double machine learning"
  },
  {
    "objectID": "exercises_html/2_exercise.html",
    "href": "exercises_html/2_exercise.html",
    "title": "Machine learning course for VIVE",
    "section": "",
    "text": "This notebook consists of two independent parts. The first about basic Python where you get familiar with the most important concepts and tools. The second part is a short introduction to pandas, which is a tool for structuring data in Python, and numpy, which is a tool for matrix calculations.\n\n\nIn this integrated assignment and teaching module, we will learn the following things about basic Python: - Fundamental data types: numeric, string and boolean - Operators: numerical and logical - Conditional logic - Containers with indices - Loops: for and while - Reuseable code: functions, classes and modules\nAdditional sources:\nAs always, there are many sources out there: Google is your best friend. However, here are some recommendations\n\nA book: Python for Data Analysis\nVideos: pythonprogramming.net fundamental (basics and intermediate)\nA tutorial website: The official python 3 tutorial (sections 3, 4 and 5)"
  },
  {
    "objectID": "exercises_html/2_exercise.html#elementary-data-types",
    "href": "exercises_html/2_exercise.html#elementary-data-types",
    "title": "Machine learning course for VIVE",
    "section": "Elementary Data Types",
    "text": "Elementary Data Types\n\nExamples with data types\nExecute the code below to create a variable A as a float equal to 1.5:\n\nA = 1.5\n\nExecute the code below to convert the variable A to an integer by typing:\n\nint(A) # rounds down, i.e. floor \n\n1\n\n\nWe can do the same for converting to float, str, bool. Note some may at first come across as slightly odd:\n\nbool(A)\n\nTrue\n\n\nWhile some are simply not allowed:\n\nfloat('A') # Attempt at converting the string (text) 'A' to a number\n\nValueError: could not convert string to float: 'A'"
  },
  {
    "objectID": "exercises_html/2_exercise.html#printing-stuff",
    "href": "exercises_html/2_exercise.html#printing-stuff",
    "title": "Machine learning course for VIVE",
    "section": "Printing Stuff",
    "text": "Printing Stuff\nAn essential procedure in Python is print. Try executing some code - in this case, printing a string of text:\n\nmy_str = 'I can do in Python, whatever I want' # define a string of text\nprint(my_str) # print it\n\nI can do in Python, whatever I want\n\n\nWe can also print several objects at the same time. Try it!\n\nmy_var1 = 33\nmy_var2 = 2\nprint(my_var1, my_var2)\n\n33 2\n\n\nWhy do we print? - It allows us to inspect values - For instance when trying to understand why a piece of code does not give us what we expect (i.e. debugging) - In particular helpful when inspecting intermediate output (within a function, loops etc.)."
  },
  {
    "objectID": "exercises_html/2_exercise.html#numeric-operators",
    "href": "exercises_html/2_exercise.html#numeric-operators",
    "title": "Machine learning course for VIVE",
    "section": "Numeric Operators",
    "text": "Numeric Operators\nWhat numeric computations can python do?\nAn operator in Python manipulates various data types.\nWe have seen addition +. Other basic numeric operators: - multiplication *; - subtraction -; - division /; - power, **\nTry executing the code below. Explain in words what the expression does.\n\n2**4 \n\n16\n\n\n\nProblem 1.1\nHaving seen all the information, you are now ready for the first exercise. The exercise is found below in the indented text. > Ex. 1.1: Add the two integers 3 and 5\n\n### BEGIN SOLUTION\n\n\n\nProblem 1.2\nPython also has a built in data type called a string. This is simply a sequence of letters/characters and can thus contain names, sentences etc. To define a string in python, you need to wrap your sentence in either double or single quotation marks. For example you could write \"Hello world!\".\n\nEx. 1.2: In Python the + is not only used for numbers. Use the + to add together the three strings \"VIVE\", \"Machine\" and \"Learning\". What is the result?\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#boolean-operators",
    "href": "exercises_html/2_exercise.html#boolean-operators",
    "title": "Machine learning course for VIVE",
    "section": "Boolean Operators",
    "text": "Boolean Operators\nHelpful advice: If you are not certain what a boolean value is, try and go back to Fundamental Data Types\nWhat else can operators do?\nWe can check the validity of a statement - using the equal operator, ==, or not equal operator !=. Try the examples below:\n\n3 == (2 + 1)\n\nTrue\n\n\n\n3 != (2 + 1)\n\nFalse\n\n\n\n11 != 2 * 5\n\nTrue\n\n\nIn all these cases, the outcomes were boolean.\nWe can also do numeric comparisons, such as greater than >, greater than or equal >=, etc.:\n\n11 <= 2 * 5\n\nFalse\n\n\nHow can we manipulate boolean values?\nCombining boolean values can be done using:\n\nthe and operator - equivalent to &\nthe or operator - equivalent to |\n\nLet’s try this!\n\nprint(True | False)\nprint(True & False)\n\nTrue\nFalse\n\n\nWhat other things can we do?\nWe can negate/reverse the statement with the not operator:\n\nnot (True and False)\n\nTrue\n\n\n\nProblem 1.3\nAbove you added two integers together, and got a result of 8. Python separates numbers in two classes, the integers \\(...,-1,0,1,2,...\\) and the floats, which are an approximation of the real numbers \\(\\mathbb{R}\\) (exactly how floats differ from reals is taught in introductory computer science courses).\n\nEx. 1.3:\n* Add 1.7 to 4 * What type is 0.667 * 100 in Python?\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#containers",
    "href": "exercises_html/2_exercise.html#containers",
    "title": "Machine learning course for VIVE",
    "section": "Containers",
    "text": "Containers\nWhat is a composite data type?\nA data type that can contain more than entry of data, e.g. multiple numbers.\nWhat are the most fundamental composite data types?\nThree of the most fundamental composite data types are the tuple, the list and the dictionary.\n\nThe tuple is declared with round parentheses, e.g. (1, 2, 3) each element in the tuple is separated by a comma. One you have declared a tuple you cannot change it’s content without making a copy of the tuple first (you will read that the tuple is an immutable data type).\nThe list is almost identical to the tuple. It is declared using square parentheses, e.g. [1, 2, 3]. Unlike the tuple, a list can be changed after definition, by adding, changing or removing elements. This is called a mutable data type.\nThe dictionary or simply dict is also a mutable data type. Unlike the other data types the dict works like a lookup table, where each element of data stored in the dictionary is associated with a name. To look up an item in the dictionary you don’t need to know its position in the dictionary, only its name. The dict is defined with curly braces and a colon to separate the name from the value, e.g. {'name_of_first_entry': 1, 'name_of_second_entry: 2}.\n\n\nProblem 1.4\n\nEx. 1.4: Define the variable y as a list containing the elements 'k', 2, 'b', 9. Also define a variable z which is a tuple containing the same elements. Try to access the 0th element of y (python is 0-indexed) and the 1st element of z.\nHint: To access the n’th element of a list/tuple write myData[n], for example y[0] gets the 0th element of y.\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#if-then-syntax",
    "href": "exercises_html/2_exercise.html#if-then-syntax",
    "title": "Machine learning course for VIVE",
    "section": "If-then syntax",
    "text": "If-then syntax\nControl flow means writing code that controls the way data or information flows through the program. The concepts of control flow should be recognizable outside of coding as well. For example when you go shopping you might want to buy koldskål, but only if the kammerjunker are on sale. else you will buy icecream. These kinds of logic come up everywhere in coding; self driving cars should go forward only if the light is green, items should be listed for sale in a web shop only if they are in stock, stars should be put on the estimates if they are significant etc.\nAnother kind of control flow deals with doing things repeatedly. For example dishes should be done while there are still dirty dishes to wash, for each student in a course a grade should be given, etc.\nIn the following problems you will work with both kinds of control flow.\nHow can we activate code based on data in Python?\nIn Python, the syntax is easy with the if syntax.\nif statement:  \n    code\nIn the example above, the block called code is run if the condition called statement is true (either a variable or an expression).\n\nExamples using if\nTry to run the examples:\n\nmy_statement = (4 == 4)\nif my_statement:  \n    print (\"I'm being executed, yay!\")\n\nI'm being executed, yay!\n\n\n\n\nIntroducing an alternative\nIf the statement in our condition is false, then we can execute other code with the else statement. Try the example below - and change the boolean value of my_statement.\n\nmy_statement = False\nif my_statement:  \n    print (\"I'm being executed, yay!\")\nelse:\n    print (\"Shoot! I'm still being executed!\")\n\nShoot! I'm still being executed!\n\n\n\n\nOptional material\nWe have not covered the statements break and continue, or try and except which are also control flow statements. These are slightly more advanced, but it can be a good idea to look them up yourself.\nIn Python the if/else logic consists of three keywords: if, elif (else if) and else. The if and elif keywords should be followed by a logical statement that is either True or False. The code that should be executed if the logic is True is written on the lines below the if, and should be indented one TAB (or 4 spaces). Finally all control flow statements must end with a colon.\n\nEx. 2.1: Read the code in the cell below. Assign a value to the variable x that makes the code print “Good job!”\n\n\n### BEGIN SOLUTION\nx = \n\nif x > 5:\n    print(\"x is too large\")\n\nelif x >= 3 and x <= 5:\n    print(\"Good job!\")\n\nelse:   \n    print(\"x is too small\")\n    \n\nAbove we used two different types of comparison: >= and <. To compare two values and check whether they are equal, python uses double equal signs == (remember a single = was used to assign values to a variable).\n\nEx. 2.2: The code below draws a random number between 0 and 1 and stores in the variable randnum. Write an if/else block that defines a new variable which is equal to 1 if randnum <= 0.1 and is 0 if randnum > 0.1.\n\n\nimport random\nrandnum = random.uniform(0,1)\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#loops",
    "href": "exercises_html/2_exercise.html#loops",
    "title": "Machine learning course for VIVE",
    "section": "Loops",
    "text": "Loops\n\nFor loops\nControl flow that does the same thing repeatedly is called a loop. In python you can loop through anything that is iterable, e.g. anything where it makes sense to say “for each element in this item, do whatever.”\nLists, tuples and dictionaries are all iterable, and can thus be looped over. This kind of loop is called a for loop. The basic syntax is\nfor element in some_iterable:\n    do_something(element)\nwhere element is a temporary name given to the current element reached in the loop, and do_something can be any valid python function applied to element.\nExample - try the following code:\n\nA = []\n\nfor i in [1, 3, 5]:\n    i_squared = i ** 2\n    A.append(i_squared)\n    \nprint(A)\n\n[1, 9, 25]\n\n\nFor loops are smart when: iterating over files in a directory; iterating over specific set of columns.\nQuiz: How does Python know where the code associated with inside of the loop begins?\nAnswer:\n\nEx. 2.3: Begin by initializing an emply list in the variable answer_23 (simply write answer_23 = []). Then loop trough the list y that you defined in problem 1.4. For each element in y, multiply that element by 7 and append it to answer_23. (You can finish off by showing the content of answer_23 after the loop has run.)\n\n\nHint: To append data to a list you can write answer_23.append(new_element) where new_element is the new data that you want to append.\n\n\n### BEGIN SOLUTION\n\n\n\nWhile loops\nThe other kind of loop in Python is the while loop. Instead of looping over an iterable, the while loop continues going as long as a supplied logical condition is True.\nMost commonly, the while loop is combined with a counting variable that keeps track of how many times the loop has been run.\nOne specific application where a while loop can be useful is data collection on the internet (scraping) which is often open ended. Another application is when we are computing something that we do not know how long will take to compute, e.g. when a model is being estimated.\nThe basic syntax is seen in the example below. This code will run 100 times before stopping. At each iteration, it checks that i is smaller than 100. If it is, it does something and adds 1 to the variable i before repeating.\n\ni = 0\nwhile i < 100:\n    do_something()    \n    i = i + 1\nIn the example below, we provide an example of what do_something() can be. Try the code below and explain why it outputs what it does.\n\ni = 0\nL = []\nwhile (i < 5):\n    L.append(i * 3)\n    i += 1\n\nprint(L)    \n\n[0, 3, 6, 9, 12]\n\n\n\n\nProblem 2.4\n\nEx. 2.4: Begin by defining an empty list. Write a while loop that runs from \\(i=0\\) up to but not including \\(i=1500\\). In each loop, it should determine whether the current value of i is a multiple of 19. If it is, append the number to the list. (recall that \\(i\\) is divisible by \\(a\\) if \\(i \\text{ mod } a = 0\\). The modulo operator in python is %)\n\n\nHint: The if statement does not need to be followed by an else. You can simply code the if part and python will automatically skip it and continue if the logical condition is False.\nHint: Remember to increment i in each iteration. Otherwise the program will run forever. If this happens, press kernel > interrupt in the menu bar.\n\n\ni = 0\nanswer_24 = []\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#functions",
    "href": "exercises_html/2_exercise.html#functions",
    "title": "Machine learning course for VIVE",
    "section": "Functions",
    "text": "Functions\nIf you have never programmed in anything but statistical software such as Stata or SAS, the concept of functions might be new to you. In python, a function is simply a “recipe” that is first written, and then later used to compute something.\nConceptually, functions in programming are similar to functions in math. They have between \\(0\\) and “\\(\\infty\\)” inputs, do some calculation using their inputs and then return between 1 and “\\(\\infty\\)” outputs.\nBy making these recipes, we can save time by making a concise function that undertakes exactly the task that we want to complete.\nPython contains a large number of built-in functions. Below, you are given examples of how to use the most commonly used built-ins. You should make yourself comfortable using each of the functions shown below.\n\n# Setup for the examples. We define two lists to show you the built-in functions.\nl1 = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\nl2 = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n\n\n# The len(x) function gives you the length of the input\nlen(l2)\n\n10\n\n\n\n# The abs(x) function returns the absolute value of x\nabs(-5)\n\n5\n\n\n\n# The min(x) and max(x) functions return the minimum and maximum of the input.\nmin(l1), max(l1)\n\n(0, 90)\n\n\n\n# The map(function, Iterable) function applies the supplied function to each element in Iterable:\n# Note that the list() call just converts the result to a list\nlist(map(len, l2))\n\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\n\n\n# The range([start], stop, [step]) function returns a range of numbers from `start` to `stop`, in increments of `step`.\n# The values in [] are optional.\n# If no start value is set, it defaults to 0.\n# If no step value is set it defaults to 1. \n# A stop value must always be set.\n\nprint(\"Range from 0 to 100, step=1:\", range(100))\nprint(\"Range from 0 to 100, step=2:\", range(0, 100, 2))\nprint(\"Range from 10 to 65, step=3:\", range(10, 65, 3))\n\nRange from 0 to 100, step=1: range(0, 100)\nRange from 0 to 100, step=2: range(0, 100, 2)\nRange from 10 to 65, step=3: range(10, 65, 3)\n\n\n\n# The reversed(x) function reverses the input.\n# We can then loop trough it backwards\nl1_reverse = reversed(l1)\n\nfor e in l1_reverse:\n    print(e)\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\n\n\n# The enumerate(x) function returns the index of the item as well as the item itself in sequence.\n# With it, you can loop through things while keeping track of their position:\nl2_enumerate = enumerate(l2)\n\nfor index, element in l2_enumerate:\n    print(index, element)\n\n0 a\n1 b\n2 c\n3 d\n4 e\n5 f\n6 g\n7 h\n8 i\n9 j\n\n\n\n# The zip(x,y,...) function \"zips\" together two or more iterables allowing you to loop through them pairwise:\nl1l2_zip = zip(l1, l2)\n\nfor e1, e2 in l1l2_zip:\n    print(e1, e2)\n\n0 a\n10 b\n20 c\n30 d\n40 e\n50 f\n60 g\n70 h\n80 i\n90 j\n\n\n\nThe how\nYou can also write your own python functions. A python function is defined with the def keyword, followed by a user-defined name of the function, the inputs to the function and a colon. On the following lines, the function body is written, indented by one TAB.\nFunctions use the keyword return to signal what values the function should return after doing its calculations on the inputs. For example, we can define a function named my_first_function seen in the cell below. Run the code below and explain the printed output.\n\ndef my_first_function(x): # takes input x\n    x_squared = x ** 2 # x squared\n    return x_squared + 1\n\nprint('Output for input of 0: ', my_first_function(0))\nprint('Output for input of 1: ', my_first_function(1))\nprint('Output for input of 2: ', my_first_function(2))\nprint('Output for input of 3: ', my_first_function(3))\n\nOutput for input of 0:  1\nOutput for input of 1:  2\nOutput for input of 2:  5\nOutput for input of 3:  10\n\n\nWe can also make more complex functions. The function below, named my_second_function, takes two inputs a and b that is used to compute the values \\(a^b\\) (written in python as a ** b) and \\(b^a\\) and returns the larger of the two.\nProvide the function below with different inputs of a and b. Explain the output to yourself.\n\ndef my_second_function(a, b):\n    v1 = a ** b\n    v2 = b ** a\n    \n    if v1 > v2:\n        return v1\n    else:\n        return v2\n\n\n\nProblem 3.1\n\nEx. 3.1: Write a function called minimum that takes as input a list of numbers, and returns the index and value of the minimum number as a tuple. Use your function to calculate the index and value of the minimum number in the list [-342, 195, 573, -234, 762, -175, 847, -882, 153, -22].\n\n\nHint: A “pythonic” way to keep count of the index of the minimum value would be to loop over the list of numbers by using the enumerate function on the list of numbers.\n\n\n### BEGIN SOLUTION\n\n\n\nProblem 3.2\n\nEx. 3.2: Write a function called average that takes as input a list of numbers, and returns the average of the values in the list. Use your function to calculate the average of the values [-1, 2, -3, 4, 0, -4, 3, -2, 1]\n\n\n### BEGIN SOLUTION\n\n\n\nProblem 3.3 (OPTIONAL)\nRecall that Eulers constant \\(e\\) can be calculated as \\[\ne=\\lim_{n\\rightarrow \\infty}\\left(1+\\frac{x}{n}\\right)^{n}\n\\] Of course we cannot compute the limit on a finite memory computer. Instead we can calculate approximations by taking \\(n\\) large enough.\n\nEx. 3.3: Write a function named eulers_e that takes two inputs x and n, calculates \\[\n\\left(1+\\frac{x}{n}\\right)^{n}\n\\] and returns this value. Use your function to calculate eulers_e(1, 5) and store this value in the variable answer_33.\n\n\n### BEGIN SOLUTION\n\n\n\nProblem 3.4 (OPTIONAL)\nThe inverse of the exponential is the logarithm. Like the exponential function, there are limit definitions of the logarithm. One of these is \\[\n\\log(x) = 2 \\cdot \\sum_{k=0}^{\\infty} \\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\n\\]\nwhere \\(\\sum_{k=0}^{\\infty}\\) signifies the sum of infinitely many elements, starting from \\(k=0\\). Each element in the sum takes the value \\(\\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\\) for some \\(k\\). As before, we must approximate this with a finite sum.\n\nEx. 3.4: Define another function called natural_logarithm which takes two inputs x and k_max. In the function body calculate \\[\n2 \\cdot \\sum_{k=0}^{k\\_max} \\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\n\\] and return this value.\n\n\nHint: to calculate the sum, first initialize a value total = 0, loop through \\(k\\in \\{0, 1, \\ldots, k\\_max\\}\\) and compute \\(\\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\\). Add the computed value to your total in each step of the loop. After finalizing the loop you can then multiply the total by 2 and return the result.\n\n\n### BEGIN SOLUTION\n\n\n\nProblem 3.5 (OPTIONAL)\nJust like numbers, strings and data types, python treats functions as an object. This means you can write functions, that take a function as input and functions that return functions after being executed. This is sometimes a useful tool to have when you need to add extra functionality to an already existing function, or if you need to write function factories.\n\nEx. 3.5: Write a function called exponentiate that takes one input named func. In the body of exponentiate define a nested function (i.e. a function within a function) called with_exp that takes two inputs x and k. The nested function should return func(e, k) where e = eulers_e(x, k). The outer function should return the nested function with_exp, i.e. write something like\n\ndef exponentiate(func):\n    def with_exp(x, k):\n        e = eulers_e(x, k)\n        value = #[FILL IN]\n        return value\n    return with_exp\n\nCall the exponentiate function on natural_logarithm and store the result in a new variable called logexp.\n\n\nHint: You will not get exactly the same result as you put in due approximations and numerical accuracy.\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#an-overview",
    "href": "exercises_html/2_exercise.html#an-overview",
    "title": "Machine learning course for VIVE",
    "section": "An Overview",
    "text": "An Overview\nTabular data is like the table below. Each row is an observation which consist of two entries, one for each of the columns/fields, i.e. animal and day.\n\n\n\nindex\nAnimal\nDate\n\n\n\n\nObservation 1\nElk\nJuly 1, 2019\n\n\nObservation 2\nPig\nJuly 3, 2019\n\n\n\nWhat pandas provides is a smart way of structuring data. It has two fundamental data types, see below. These are essentially just container but come with a lot of extra functionality for structuring data and performing analysis.\n\nSeries: tabular data with a single column (field)\n\nakin to a vector in mathematics\nhas labelled columns (e.g. Animal and Date above) and named rows, called indices.\n\nDataFrame: tabular data that allows for more than one column (multiple fields)\n\nakin to a matrix in mathematics\n\n\nRun the code below to make your first pandas dataframe. Try to print it and explain the content it shows.\n\nimport pandas as pd\n\ndf1 = pd.DataFrame(data=[[1, 2],[3, 4],[5, 6],[7, 8]],\n                   index=['i', 'ii','iii','iv'],\n                   columns=['A', 'B'])\n\nThe code below makes a series from a list. We can see that it contains all the four fundamental data types!\n\nL = [1, 1.2, 'abc', True]\nser1 = pd.Series(L)\n\nNow you may ask yourself: why don’t we just use numpy?\nThere are many reasons. pandas is easier for loading, structuring and making simple analysis of tabular data. However, in many cases, if you are working with custom data or need to performing fast and complex array computations, then numpy is a better option. If you are interested see discussion here."
  },
  {
    "objectID": "exercises_html/2_exercise.html#switching-among-python-numpy-and-pandas",
    "href": "exercises_html/2_exercise.html#switching-among-python-numpy-and-pandas",
    "title": "Machine learning course for VIVE",
    "section": "Switching Among Python, Numpy and Pandas",
    "text": "Switching Among Python, Numpy and Pandas\nPandas dataframes can be thought of as numpy arrays with some additional stuff. Note that columns can have different datatypes!\nMost functions from numpy can be applied directly to Pandas. We can convert a DataFrame to a numpy array with values attribute:\n\ndf1.values\n\narray([[1, 2],\n       [3, 4],\n       [5, 6],\n       [7, 8]], dtype=int64)\n\n\nIn Python, we can describe it as a list of lists.\n\ndf1.values.tolist()\n\n[[1, 2], [3, 4], [5, 6], [7, 8]]\n\n\nBoth dataframes and series have indices which are both a blessing and a curse. These indices means that we can often convert a Series into a dictionary:\n\nser1.to_dict()\n\n{0: 1, 1: 1.2, 2: 'abc', 3: True}\n\n\nWARNING!: Series indices are NOT unique thus we may lose data if we convert to a dict which requires unique keys."
  },
  {
    "objectID": "exercises_html/2_exercise.html#inspection",
    "href": "exercises_html/2_exercise.html#inspection",
    "title": "Machine learning course for VIVE",
    "section": "Inspection",
    "text": "Inspection\nOften we want to see what our dataframe contains. This can be done by putting the dataframe at the end of our cell, then it will automatically be printed.\nThe example below consist of 100 rows, with 5 columns of random data. We see that putting the dataframe in the end prints the dataframe.\n\ndf2 = pd.DataFrame(data=np.random.rand(100, 5), \n                   columns=['A','B','C','D','E'])\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.120631\n      0.894828\n      0.797189\n      0.091109\n      0.134574\n    \n    \n      1\n      0.741095\n      0.809830\n      0.906311\n      0.051057\n      0.190558\n    \n    \n      2\n      0.217593\n      0.214831\n      0.922281\n      0.558786\n      0.728655\n    \n    \n      3\n      0.821169\n      0.762247\n      0.777922\n      0.973012\n      0.756787\n    \n    \n      4\n      0.816527\n      0.297157\n      0.521235\n      0.616021\n      0.743572\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      0.751320\n      0.910512\n      0.835192\n      0.717437\n      0.125446\n    \n    \n      96\n      0.135453\n      0.463779\n      0.532739\n      0.476379\n      0.602316\n    \n    \n      97\n      0.892760\n      0.504113\n      0.787871\n      0.894477\n      0.143704\n    \n    \n      98\n      0.802927\n      0.204300\n      0.776266\n      0.724146\n      0.626081\n    \n    \n      99\n      0.452690\n      0.906161\n      0.485432\n      0.216792\n      0.594700\n    \n  \n\n100 rows × 5 columns\n\n\n\nWe can also use head and the tail method that select respectively the first and last observations in a DataFrame. The code below prints the first four rows.\n\ndf3 = df2.head(n=4)\ndf3\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.120631\n      0.894828\n      0.797189\n      0.091109\n      0.134574\n    \n    \n      1\n      0.741095\n      0.809830\n      0.906311\n      0.051057\n      0.190558\n    \n    \n      2\n      0.217593\n      0.214831\n      0.922281\n      0.558786\n      0.728655\n    \n    \n      3\n      0.821169\n      0.762247\n      0.777922\n      0.973012\n      0.756787"
  },
  {
    "objectID": "exercises_html/2_exercise.html#input-output",
    "href": "exercises_html/2_exercise.html#input-output",
    "title": "Machine learning course for VIVE",
    "section": "Input-output",
    "text": "Input-output\nWe can load and save dataframes from our computer or the internet. Try the code below to save our dataframe as a CSV file called my_data.csv. If you are unsure what a CSV file is then check the Wikipedia description.\n\ndf3.to_csv('my_data.csv')\n\nLoading data is just as easy. Some data sources are open and easy to collect data from. They do not require formatting as they come in a table format. The code below load a CSV file on school test data from NYC.\n\nmy_url = 'https://data.cityofnewyork.us/api/views/zt9s-n5aj/rows.csv'\nmy_df = pd.read_csv(my_url)\n\nmy_df.head(10)\n\n\n\n\n\n  \n    \n      \n      DBN\n      School Name\n      Number of Test Takers\n      Critical Reading Mean\n      Mathematics Mean\n      Writing Mean\n    \n  \n  \n    \n      0\n      01M292\n      Henry Street School for International Studies\n      31.0\n      391.0\n      425.0\n      385.0\n    \n    \n      1\n      01M448\n      University Neighborhood High School\n      60.0\n      394.0\n      419.0\n      387.0\n    \n    \n      2\n      01M450\n      East Side Community High School\n      69.0\n      418.0\n      431.0\n      402.0\n    \n    \n      3\n      01M458\n      SATELLITE ACADEMY FORSYTH ST\n      26.0\n      385.0\n      370.0\n      378.0\n    \n    \n      4\n      01M509\n      CMSP HIGH SCHOOL\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      5\n      01M515\n      Lower East Side Preparatory High School\n      154.0\n      314.0\n      532.0\n      314.0\n    \n    \n      6\n      01M539\n      New Explorations into Sci, Tech and Math HS\n      47.0\n      568.0\n      583.0\n      568.0\n    \n    \n      7\n      01M650\n      CASCADES HIGH SCHOOL\n      35.0\n      411.0\n      401.0\n      401.0\n    \n    \n      8\n      01M696\n      BARD HIGH SCHOOL EARLY COLLEGE\n      138.0\n      630.0\n      608.0\n      630.0\n    \n    \n      9\n      02M047\n      AMERICAN SIGN LANG ENG DUAL\n      11.0\n      405.0\n      415.0\n      385.0\n    \n  \n\n\n\n\n\nWorking with weather data\nWe will now work with a dataset regarding weather. Our source will be National Oceanic and Atmospheric Administration (NOAA) which have a global data collection going back a couple of centuries. This collection is called Global Historical Climatology Network (GHCN). The data contains daily weather recorded at the weather stations. A description of GHCN can be found here.\n\n\nProblem 4.1\n\nEx. 4.1: Use Pandas’ CSV reader to fetch daily data weather from 1863 for various stations - available somewhere on your common drive. If you cannot find it, it can also be found at this website.\nHint: you will need to give read_csv some keywords. Here are some suggestions - Specify the path, using either a string or through the pathlib module, see documentation (nice for interoperability between macOS + Windows and relative paths). - for compressed files you may need to specify the keyword compression when calling the .read_csv method. - header can be specified as the CSV has no column names.\n\n\nimport pandas as pd\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#selecting-rows-and-columns",
    "href": "exercises_html/2_exercise.html#selecting-rows-and-columns",
    "title": "Machine learning course for VIVE",
    "section": "Selecting Rows and Columns",
    "text": "Selecting Rows and Columns\nIn pandas there are two canonical ways of accessing subsets of a dataframe. - The iloc attribute: access rows and columns using integer indices (like a list). - The loc attribute: access rows and columns using immutable keys, e.g. numbers, strings (like a dictionary).\nIn what follows we will describe some different way of selection using .iloc and .loc as well as a simpler way of simply accesing the dataframe using []. The different ways are meant to give you an overview.\n\nUsing list of keys/indices\nBelow is an example of using the iloc attribute to select specific rows:\n\ndf1 # show df1 before indexing it with .iloc[]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      i\n      1\n      2\n    \n    \n      ii\n      3\n      4\n    \n    \n      iii\n      5\n      6\n    \n    \n      iv\n      7\n      8\n    \n  \n\n\n\n\n\nmy_irows = [0, 3]\ndf1.iloc[my_irows]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      i\n      1\n      2\n    \n    \n      iv\n      7\n      8\n    \n  \n\n\n\n\nWe can select columns and rows simultaneously. Below is an example of using the loc attribute, which does that:\n\nmy_rows = ['i', 'iii']\nmy_cols = ['A']\ndf1.loc[my_rows, my_cols]\n\n\n\n\n\n  \n    \n      \n      A\n    \n  \n  \n    \n      i\n      1\n    \n    \n      iii\n      5\n    \n  \n\n\n\n\n\n\nUsing thresholds\nWe can also use iloc and loc for selecting rows and/or columns below or above some treshold, see below. Note that whether or not the : is on front determines whether it is above or below.\n\ndf2.iloc[:3, :4]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.120631\n      0.894828\n      0.797189\n      0.091109\n    \n    \n      1\n      0.741095\n      0.809830\n      0.906311\n      0.051057\n    \n    \n      2\n      0.217593\n      0.214831\n      0.922281\n      0.558786\n    \n  \n\n\n\n\n\n\nUsing boolean data\nIf we provide the dataframe with a boolean, it will select rows (also works with iloc and loc). We will see soon that this is an extremely useful way of selecting certain rows.\n\ndf3[[True, False, False, True]]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.120631\n      0.894828\n      0.797189\n      0.091109\n      0.134574\n    \n    \n      3\n      0.821169\n      0.762247\n      0.777922\n      0.973012\n      0.756787\n    \n  \n\n\n\n\n\n\nSelecting columns\nOften we need to select specific columns. If we provide the dataframe with a list of column names it will make a dataframe keep only these columns:\n\ndf3[['B', 'D']]\n\n\n\n\n\n  \n    \n      \n      B\n      D\n    \n  \n  \n    \n      0\n      0.894828\n      0.091109\n    \n    \n      1\n      0.809830\n      0.051057\n    \n    \n      2\n      0.214831\n      0.558786\n    \n    \n      3\n      0.762247\n      0.973012\n    \n  \n\n\n\n\n\n\nProblem 4.2\n\nEx 4.2: Select the four left-most columns which contain: station identifier, data, observation type, observation value. Rename them as ‘station’, ‘datetime’, ‘obs_type’, ‘obs_value’.\n\n\nHint: Renaming can be done with df.columns = cols where cols is a list of column names.\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#basic-operations",
    "href": "exercises_html/2_exercise.html#basic-operations",
    "title": "Machine learning course for VIVE",
    "section": "Basic Operations",
    "text": "Basic Operations\nHow do we perform elementary operations like we learned for basic Python? E.g. numeric operations such as summation (+) or logical operations such as greater than (>). Actually we are in luck - they are exactly the same.\nLet’s see how it works for numeric data using a numpy array (works the same way as Pandas).\n\nmy_arr1 = np.array([2, 3, 2, 1, 1])\nmy_arr2 = my_arr1 ** 2\nmy_arr2\n\narray([4, 9, 4, 1, 1])\n\n\nCan we do the same with two vectors? Yes, we can also do elementwise addition, multiplication, subtractions etc. of series. Example:\n\nmy_arr1 + my_arr2\n\narray([ 6, 12,  6,  2,  2])"
  },
  {
    "objectID": "exercises_html/2_exercise.html#changing-and-copying-data",
    "href": "exercises_html/2_exercise.html#changing-and-copying-data",
    "title": "Machine learning course for VIVE",
    "section": "Changing and Copying Data",
    "text": "Changing and Copying Data\nEverything in the dataframe can be changed. For instance, we can also update our dataframe with new values, e.g. by making new variables or overwriting existing ones. In the example below we add a new column to add a DataFrame.\n\ndf2['F'] = df2['A'] > df2['D']\ndf2.head(10)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n      F\n    \n  \n  \n    \n      0\n      0.120631\n      0.894828\n      0.797189\n      0.091109\n      0.134574\n      True\n    \n    \n      1\n      0.741095\n      0.809830\n      0.906311\n      0.051057\n      0.190558\n      True\n    \n    \n      2\n      0.217593\n      0.214831\n      0.922281\n      0.558786\n      0.728655\n      False\n    \n    \n      3\n      0.821169\n      0.762247\n      0.777922\n      0.973012\n      0.756787\n      False\n    \n    \n      4\n      0.816527\n      0.297157\n      0.521235\n      0.616021\n      0.743572\n      True\n    \n    \n      5\n      0.145407\n      0.042439\n      0.326667\n      0.419953\n      0.199158\n      False\n    \n    \n      6\n      0.432879\n      0.164140\n      0.773915\n      0.391000\n      0.390303\n      True\n    \n    \n      7\n      0.767490\n      0.436440\n      0.456701\n      0.295669\n      0.371493\n      True\n    \n    \n      8\n      0.878475\n      0.463741\n      0.707059\n      0.313607\n      0.993167\n      True\n    \n    \n      9\n      0.603135\n      0.075850\n      0.373057\n      0.238297\n      0.751641\n      True\n    \n  \n\n\n\n\nWARNING!: If you work on a subset of data from another dataframe, then this dataframe is what is known as a view! Therefore, all changes made in the view will also be made in the original version.\nIn the example below, we try to change the dataframe df2 which is a view of df3, and we get a warning. Thus, changes to df3 also happen in df2. Notice that we can also use loc for changing the data.\n\ndf3.loc[:,'D'] = df3['A'] - df3['E']\nprint(df2['D'].head(3), '\\n')\nprint(df3['D'].head(3))\n\n0   -0.013944\n1    0.550537\n2   -0.511063\nName: D, dtype: float64 \n\n0   -0.013944\n1    0.550537\n2   -0.511063\nName: D, dtype: float64\n\n\nC:\\Users\\wkg579\\AppData\\Local\\Temp\\ipykernel_5704\\2462267356.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df3.loc[:,'D'] = df3['A'] - df3['E']\n\n\nTo avoid the problem of having a view, we can instead copy the data as in the example below. Try to verify that if you change things in df4 things do not change in df2.\n\ndf4 = df2.copy()\n\n\n# Verify that the code from above doesn't throw the same \"SettingWithCopyWarning\" \n# when using the copied dataframe, df4, instead of df3.\ndf4.loc[:, 'D'] = df4['A'] - df4['E']\n\n\nProblem 4.3\n\nEx. 4.3: Further, select the subset of data for the station UK000056225 and only observations for maximal temperature. Make a copy of the DataFrame and store this in the variable df_select. Explain in a one or two sentences how copying works. Write your answer in a multi line comment like \"\"\" Your answer here \"\"\".\n\n\nHint: The & operator works elementwise on boolean series (like and in core python). This allows to combine conditions for selections.\n\n\n### BEGIN SOLUTION\n\n\n\nProblem 4.4\n\nEx 4.4: Make sure that max temperature is correctly formated (how many decimals should we add? one? Look through this .txt file for an answer https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt). Make a new column called TMAX_F where you have converted the temperature variables to Fahrenheit.\n\n\nHint: Conversion is \\(F = 32 + 1.8*C\\) where \\(F\\) is Fahrenheit and \\(C\\) is Celsius.\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise.html#changing-and-rearranging-indices",
    "href": "exercises_html/2_exercise.html#changing-and-rearranging-indices",
    "title": "Machine learning course for VIVE",
    "section": "Changing and Rearranging Indices",
    "text": "Changing and Rearranging Indices\nIn addition to replacing values of our data, we can also rearrange the order of variables and rows as well as make new ones. We have already seen how to change column names but we can also reset the index, as seen below. Alternatively, we can set our own custom index using set_index, with temporal data etc. which provides the DataFrame with new functionality.\n\ndf1_new_index = df1.reset_index(drop=True)\ndf1_new_index\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      5\n      6\n    \n    \n      3\n      7\n      8\n    \n  \n\n\n\n\nA powerful tool for re-organizing the data is to sort the data. That is, we can re-organize rows (or columns) such that they are ascending or descending according to one or more columns.\n\ndf3_sorted = df3.sort_values(by=['A','B'], ascending=True)\ndf3_sorted\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.120631\n      0.894828\n      0.797189\n      -0.013944\n      0.134574\n    \n    \n      2\n      0.217593\n      0.214831\n      0.922281\n      -0.511063\n      0.728655\n    \n    \n      1\n      0.741095\n      0.809830\n      0.906311\n      0.550537\n      0.190558\n    \n    \n      3\n      0.821169\n      0.762247\n      0.777922\n      0.064383\n      0.756787\n    \n  \n\n\n\n\n\nProblem 4.5\n\nEx 4.5: Inspect the indices in df_select. Are they following the sequence of natural numbers, 0,1,2,…? If not, reset the index and make sure to drop the old.\n\n\n### BEGIN SOLUTION\n\n\n\nProblem 4.6\n\nEx 4.6: Make a new DataFrame df_sorted where you have sorted by the maximum temperature. What is the date for the first and last observations?\n\n\n### BEGIN SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html",
    "href": "exercises_html/2_exercise_sol.html",
    "title": "Machine learning course for VIVE",
    "section": "",
    "text": "This notebook consists of two independent parts. The first about basic Python where you get familiar with the most important concepts and tools. The second part is a short introduction to pandas, which is a tool for structuring data in Python, and numpy, which is a tool for matrix calculations.\n\n\nIn this integrated assignment and teaching module, we will learn the following things about basic Python: - Fundamental data types: numeric, string and boolean - Operators: numerical and logical - Conditional logic - Containers with indices - Loops: for and while - Reuseable code: functions, classes and modules\nAdditional sources:\nAs always, there are many sources out there: Google is your best friend. However, here are some recommendations\n\nA book: Python for Data Analysis\nVideos: pythonprogramming.net fundamental (basics and intermediate)\nA tutorial website: The official python 3 tutorial (sections 3, 4 and 5)"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#elementary-data-types",
    "href": "exercises_html/2_exercise_sol.html#elementary-data-types",
    "title": "Machine learning course for VIVE",
    "section": "Elementary Data Types",
    "text": "Elementary Data Types\n\nExamples with data types\nExecute the code below to create a variable A as a float equal to 1.5:\n\nA = 1.5\n\nExecute the code below to convert the variable A to an integer by typing:\n\nint(A) # rounds down, i.e. floor \n\n1\n\n\nWe can do the same for converting to float, str, bool. Note some may at first come across as slightly odd:\n\nbool(A)\n\nTrue\n\n\nWhile some are simply not allowed:\n\n#float('A') # Attempt at converting the string (text) 'A' to a number"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#printing-stuff",
    "href": "exercises_html/2_exercise_sol.html#printing-stuff",
    "title": "Machine learning course for VIVE",
    "section": "Printing Stuff",
    "text": "Printing Stuff\nAn essential procedure in Python is print. Try executing some code - in this case, printing a string of text:\n\nmy_str = 'I can do in Python, whatever I want' # define a string of text\nprint(my_str) # print it\n\nI can do in Python, whatever I want\n\n\nWe can also print several objects at the same time. Try it!\n\nmy_var1 = 33\nmy_var2 = 2\nprint(my_var1, my_var2)\n\n33 2\n\n\nWhy do we print? - It allows us to inspect values - For instance when trying to understand why a piece of code does not give us what we expect (i.e. debugging) - In particular helpful when inspecting intermediate output (within a function, loops etc.)."
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#numeric-operators",
    "href": "exercises_html/2_exercise_sol.html#numeric-operators",
    "title": "Machine learning course for VIVE",
    "section": "Numeric Operators",
    "text": "Numeric Operators\nWhat numeric computations can python do?\nAn operator in Python manipulates various data types.\nWe have seen addition +. Other basic numeric operators: - multiplication *; - subtraction -; - division /; - power, **\nTry executing the code below. Explain in words what the expression does.\n\n2**4 \n\n16\n\n\n\nProblem 1.1\nHaving seen all the information, you are now ready for the first exercise. The exercise is found below in the indented text. > Ex. 1.1: Add the two integers 3 and 5\n\n### BEGIN SOLUTION\n\nanswer_11 = 3 + 5\n\n### END SOLUTION\n\n\n\nProblem 1.2\nPython also has a built in data type called a string. This is simply a sequence of letters/characters and can thus contain names, sentences etc. To define a string in python, you need to wrap your sentence in either double or single quotation marks. For example you could write \"Hello world!\".\n\nEx. 1.2: In Python the + is not only used for numbers. Use the + to add together the three strings \"VIVE\", \"Machine\" and \"Learning\". What is the result?\n\n\n### BEGIN SOLUTION\n\nanswer_12 = 'VIVE' + 'Machine' + 'Learning'\n\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#boolean-operators",
    "href": "exercises_html/2_exercise_sol.html#boolean-operators",
    "title": "Machine learning course for VIVE",
    "section": "Boolean Operators",
    "text": "Boolean Operators\nHelpful advice: If you are not certain what a boolean value is, try and go back to Fundamental Data Types\nWhat else can operators do?\nWe can check the validity of a statement - using the equal operator, ==, or not equal operator !=. Try the examples below:\n\n3 == (2 + 1)\n\nTrue\n\n\n\n3 != (2 + 1)\n\nFalse\n\n\n\n11 != 2 * 5\n\nTrue\n\n\nIn all these cases, the outcomes were boolean.\nWe can also do numeric comparisons, such as greater than >, greater than or equal >=, etc.:\n\n11 <= 2 * 5\n\nFalse\n\n\nHow can we manipulate boolean values?\nCombining boolean values can be done using:\n\nthe and operator - equivalent to &\nthe or operator - equivalent to |\n\nLet’s try this!\n\nprint(True | False)\nprint(True & False)\n\nTrue\nFalse\n\n\nWhat other things can we do?\nWe can negate/reverse the statement with the not operator:\n\nnot (True and False)\n\nTrue\n\n\n\nProblem 1.3\nAbove you added two integers together, and got a result of 8. Python separates numbers in two classes, the integers \\(...,-1,0,1,2,...\\) and the floats, which are an approximation of the real numbers \\(\\mathbb{R}\\) (exactly how floats differ from reals is taught in introductory computer science courses).\n\nEx. 1.3:\n* Add 1.7 to 4 * What type is 0.667 * 100 in Python?\n\n\n### BEGIN SOLUTION\nanswer_131 = 1.3 + 4\nanswer_132 = 0.667 * 100 \n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#containers",
    "href": "exercises_html/2_exercise_sol.html#containers",
    "title": "Machine learning course for VIVE",
    "section": "Containers",
    "text": "Containers\nWhat is a composite data type?\nA data type that can contain more than entry of data, e.g. multiple numbers.\nWhat are the most fundamental composite data types?\nThree of the most fundamental composite data types are the tuple, the list and the dictionary.\n\nThe tuple is declared with round parentheses, e.g. (1, 2, 3) each element in the tuple is separated by a comma. One you have declared a tuple you cannot change it’s content without making a copy of the tuple first (you will read that the tuple is an immutable data type).\nThe list is almost identical to the tuple. It is declared using square parentheses, e.g. [1, 2, 3]. Unlike the tuple, a list can be changed after definition, by adding, changing or removing elements. This is called a mutable data type.\nThe dictionary or simply dict is also a mutable data type. Unlike the other data types the dict works like a lookup table, where each element of data stored in the dictionary is associated with a name. To look up an item in the dictionary you don’t need to know its position in the dictionary, only its name. The dict is defined with curly braces and a colon to separate the name from the value, e.g. {'name_of_first_entry': 1, 'name_of_second_entry: 2}.\n\n\nProblem 1.4\n\nEx. 1.4: Define the variable y as a list containing the elements 'k', 2, 'b', 9. Also define a variable z which is a tuple containing the same elements. Try to access the 0th element of y (python is 0-indexed) and the 1st element of z.\nHint: To access the n’th element of a list/tuple write myData[n], for example y[0] gets the 0th element of y.\n\n\n### BEGIN SOLUTION\n\ny = ['k', 2, 'b', 9]\nz = ('k', 2, 'b', 9)\n\nanswer_14_y0 = y[0]\nanswer_14_z1 = z[1]\n\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#if-then-syntax",
    "href": "exercises_html/2_exercise_sol.html#if-then-syntax",
    "title": "Machine learning course for VIVE",
    "section": "If-then syntax",
    "text": "If-then syntax\nControl flow means writing code that controls the way data or information flows through the program. The concepts of control flow should be recognizable outside of coding as well. For example when you go shopping you might want to buy koldskål, but only if the kammerjunker are on sale. else you will buy icecream. These kinds of logic come up everywhere in coding; self driving cars should go forward only if the light is green, items should be listed for sale in a web shop only if they are in stock, stars should be put on the estimates if they are significant etc.\nAnother kind of control flow deals with doing things repeatedly. For example dishes should be done while there are still dirty dishes to wash, for each student in a course a grade should be given, etc.\nIn the following problems you will work with both kinds of control flow.\nHow can we activate code based on data in Python?\nIn Python, the syntax is easy with the if syntax.\nif statement:  \n    code\nIn the example above, the block called code is run if the condition called statement is true (either a variable or an expression).\n\nExamples using if\nTry to run the examples:\n\nmy_statement = (4 == 4)\nif my_statement:  \n    print (\"I'm being executed, yay!\")\n\nI'm being executed, yay!\n\n\n\n\nIntroducing an alternative\nIf the statement in our condition is false, then we can execute other code with the else statement. Try the example below - and change the boolean value of my_statement.\n\nmy_statement = False\nif my_statement:  \n    print (\"I'm being executed, yay!\")\nelse:\n    print (\"Shoot! I'm still being executed!\")\n\nShoot! I'm still being executed!\n\n\n\n\nOptional material\nWe have not covered the statements break and continue, or try and except which are also control flow statements. These are slightly more advanced, but it can be a good idea to look them up yourself.\nIn Python the if/else logic consists of three keywords: if, elif (else if) and else. The if and elif keywords should be followed by a logical statement that is either True or False. The code that should be executed if the logic is True is written on the lines below the if, and should be indented one TAB (or 4 spaces). Finally all control flow statements must end with a colon.\n\nEx. 2.1: Read the code in the cell below. Assign a value to the variable x that makes the code print “Good job!”\n\n\n### BEGIN SOLUTION\nx = 4\n### END SOLUTION\n\nif x > 5:\n    print(\"x is too large\")\n\nelif x >= 3 and x <= 5:\n    print(\"Good job!\")\n\nelse:   \n    print(\"x is too small\")\n    \n\nGood job!\n\n\nAbove we used two different types of comparison: >= and <. To compare two values and check whether they are equal, python uses double equal signs == (remember a single = was used to assign values to a variable).\n\nEx. 2.2: The code below draws a random number between 0 and 1 and stores in the variable randnum. Write an if/else block that defines a new variable which is equal to 1 if randnum <= 0.1 and is 0 if randnum > 0.1.\n\n\nimport random\nrandnum = random.uniform(0,1)\n\n### BEGIN SOLUTION\nif randnum <= 0.1:\n    answer_22 = 1\nelse:\n    answer_22 = 0\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#loops",
    "href": "exercises_html/2_exercise_sol.html#loops",
    "title": "Machine learning course for VIVE",
    "section": "Loops",
    "text": "Loops\n\nFor loops\nControl flow that does the same thing repeatedly is called a loop. In python you can loop through anything that is iterable, e.g. anything where it makes sense to say “for each element in this item, do whatever.”\nLists, tuples and dictionaries are all iterable, and can thus be looped over. This kind of loop is called a for loop. The basic syntax is\nfor element in some_iterable:\n    do_something(element)\nwhere element is a temporary name given to the current element reached in the loop, and do_something can be any valid python function applied to element.\nExample - try the following code:\n\nA = []\n\nfor i in [1, 3, 5]:\n    i_squared = i ** 2\n    A.append(i_squared)\n    \nprint(A)\n\n[1, 9, 25]\n\n\nFor loops are smart when: iterating over files in a directory; iterating over specific set of columns.\nQuiz: How does Python know where the code associated with inside of the loop begins?\nAnswer: By indenting the line with four whitespaces, see example above. This is the same as the if statements.\n\nEx. 2.3: Begin by initializing an emply list in the variable answer_23 (simply write answer_23 = []). Then loop trough the list y that you defined in problem 1.4. For each element in y, multiply that element by 7 and append it to answer_23. (You can finish off by showing the content of answer_23 after the loop has run.)\n\n\nHint: To append data to a list you can write answer_23.append(new_element) where new_element is the new data that you want to append.\n\n\n### BEGIN SOLUTION\ny = ['k', 2, 'b', 9]\nanswer_23 = [] \nfor element in y:\n    answer_23.append(7 * element)\nprint(answer_23)\n### END SOLUTION\n\n['kkkkkkk', 14, 'bbbbbbb', 63]\n\n\n\n\nWhile loops\nThe other kind of loop in Python is the while loop. Instead of looping over an iterable, the while loop continues going as long as a supplied logical condition is True.\nMost commonly, the while loop is combined with a counting variable that keeps track of how many times the loop has been run.\nOne specific application where a while loop can be useful is data collection on the internet (scraping) which is often open ended. Another application is when we are computing something that we do not know how long will take to compute, e.g. when a model is being estimated.\nThe basic syntax is seen in the example below. This code will run 100 times before stopping. At each iteration, it checks that i is smaller than 100. If it is, it does something and adds 1 to the variable i before repeating.\n\ni = 0\nwhile i < 100:\n    do_something()    \n    i = i + 1\nIn the example below, we provide an example of what do_something() can be. Try the code below and explain why it outputs what it does.\n\ni = 0\nL = []\nwhile (i < 5):\n    L.append(i * 3)\n    i += 1\n\nprint(L)    \n\n[0, 3, 6, 9, 12]\n\n\n\n\nProblem 2.4\n\nEx. 2.4: Begin by defining an empty list. Write a while loop that runs from \\(i=0\\) up to but not including \\(i=1500\\). In each loop, it should determine whether the current value of i is a multiple of 19. If it is, append the number to the list. (recall that \\(i\\) is divisible by \\(a\\) if \\(i \\text{ mod } a = 0\\). The modulo operator in python is %)\n\n\nHint: The if statement does not need to be followed by an else. You can simply code the if part and python will automatically skip it and continue if the logical condition is False.\nHint: Remember to increment i in each iteration. Otherwise the program will run forever. If this happens, press kernel > interrupt in the menu bar.\n\n\ni = 0\nanswer_24 = []\n### BEGIN SOLUTION\nwhile i < 1500:\n    if i % 19 == 0:\n        answer_24.append(i)\n    i += 1\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#functions",
    "href": "exercises_html/2_exercise_sol.html#functions",
    "title": "Machine learning course for VIVE",
    "section": "Functions",
    "text": "Functions\nIf you have never programmed in anything but statistical software such as Stata or SAS, the concept of functions might be new to you. In python, a function is simply a “recipe” that is first written, and then later used to compute something.\nConceptually, functions in programming are similar to functions in math. They have between \\(0\\) and “\\(\\infty\\)” inputs, do some calculation using their inputs and then return between 1 and “\\(\\infty\\)” outputs.\nBy making these recipes, we can save time by making a concise function that undertakes exactly the task that we want to complete.\nPython contains a large number of built-in functions. Below, you are given examples of how to use the most commonly used built-ins. You should make yourself comfortable using each of the functions shown below.\n\n# Setup for the examples. We define two lists to show you the built-in functions.\nl1 = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\nl2 = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n\n\n# The len(x) function gives you the length of the input\nlen(l2)\n\n10\n\n\n\n# The abs(x) function returns the absolute value of x\nabs(-5)\n\n5\n\n\n\n# The min(x) and max(x) functions return the minimum and maximum of the input.\nmin(l1), max(l1)\n\n(0, 90)\n\n\n\n# The map(function, Iterable) function applies the supplied function to each element in Iterable:\n# Note that the list() call just converts the result to a list\nlist(map(len, l2))\n\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\n\n\n# The range([start], stop, [step]) function returns a range of numbers from `start` to `stop`, in increments of `step`.\n# The values in [] are optional.\n# If no start value is set, it defaults to 0.\n# If no step value is set it defaults to 1. \n# A stop value must always be set.\n\nprint(\"Range from 0 to 100, step=1:\", range(100))\nprint(\"Range from 0 to 100, step=2:\", range(0, 100, 2))\nprint(\"Range from 10 to 65, step=3:\", range(10, 65, 3))\n\nRange from 0 to 100, step=1: range(0, 100)\nRange from 0 to 100, step=2: range(0, 100, 2)\nRange from 10 to 65, step=3: range(10, 65, 3)\n\n\n\n# The reversed(x) function reverses the input.\n# We can then loop trough it backwards\nl1_reverse = reversed(l1)\n\nfor e in l1_reverse:\n    print(e)\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\n\n\n# The enumerate(x) function returns the index of the item as well as the item itself in sequence.\n# With it, you can loop through things while keeping track of their position:\nl2_enumerate = enumerate(l2)\n\nfor index, element in l2_enumerate:\n    print(index, element)\n\n0 a\n1 b\n2 c\n3 d\n4 e\n5 f\n6 g\n7 h\n8 i\n9 j\n\n\n\n# The zip(x,y,...) function \"zips\" together two or more iterables allowing you to loop through them pairwise:\nl1l2_zip = zip(l1, l2)\n\nfor e1, e2 in l1l2_zip:\n    print(e1, e2)\n\n0 a\n10 b\n20 c\n30 d\n40 e\n50 f\n60 g\n70 h\n80 i\n90 j\n\n\n\nThe how\nYou can also write your own python functions. A python function is defined with the def keyword, followed by a user-defined name of the function, the inputs to the function and a colon. On the following lines, the function body is written, indented by one TAB.\nFunctions use the keyword return to signal what values the function should return after doing its calculations on the inputs. For example, we can define a function named my_first_function seen in the cell below. Run the code below and explain the printed output.\n\ndef my_first_function(x): # takes input x\n    x_squared = x ** 2 # x squared\n    return x_squared + 1\n\nprint('Output for input of 0: ', my_first_function(0))\nprint('Output for input of 1: ', my_first_function(1))\nprint('Output for input of 2: ', my_first_function(2))\nprint('Output for input of 3: ', my_first_function(3))\n\nOutput for input of 0:  1\nOutput for input of 1:  2\nOutput for input of 2:  5\nOutput for input of 3:  10\n\n\nWe can also make more complex functions. The function below, named my_second_function, takes two inputs a and b that is used to compute the values \\(a^b\\) (written in python as a ** b) and \\(b^a\\) and returns the larger of the two.\nProvide the function below with different inputs of a and b. Explain the output to yourself.\n\ndef my_second_function(a, b):\n    v1 = a ** b\n    v2 = b ** a\n    \n    if v1 > v2:\n        return v1\n    else:\n        return v2\n\n\n\nProblem 3.1\n\nEx. 3.1: Write a function called minimum that takes as input a list of numbers, and returns the index and value of the minimum number as a tuple. Use your function to calculate the index and value of the minimum number in the list [-342, 195, 573, -234, 762, -175, 847, -882, 153, -22].\n\n\nHint: A “pythonic” way to keep count of the index of the minimum value would be to loop over the list of numbers by using the enumerate function on the list of numbers.\n\n\n### BEGIN SOLUTION\ndef minimum(numbers):\n    min_num_index, min_num = float('inf'), float('inf')\n    for (number_index, value) in enumerate(numbers):\n        if value < min_num:\n            min_num_index = number_index\n            min_num = value\n    return min_num_index, min_num\n\n\n# # Alternative solution: \n# def minimum(numbers):\n#     min_value = min(numbers)\n#     idx_min_value = numbers.index(min_value)\n#     return idx_min_value, min_value\n\nnumbers = [-342, 195, 573, -234, 762, -175, 847, -882, 153, -22]\nanswer_31 = minimum(numbers)\n### END SOLUTION\n\n\n\nProblem 3.2\n\nEx. 3.2: Write a function called average that takes as input a list of numbers, and returns the average of the values in the list. Use your function to calculate the average of the values [-1, 2, -3, 4, 0, -4, 3, -2, 1]\n\n\n### BEGIN SOLUTION\ndef average(num_list):\n    return sum(num_list) / len(num_list)\nanswer_32 = average([-1, 2, -3, 4, 0, -4, 3, -2, 1])\n### END SOLUTION\n\n\n\nProblem 3.3 (OPTIONAL)\nRecall that Eulers constant \\(e\\) can be calculated as \\[\ne=\\lim_{n\\rightarrow \\infty}\\left(1+\\frac{x}{n}\\right)^{n}\n\\] Of course we cannot compute the limit on a finite memory computer. Instead we can calculate approximations by taking \\(n\\) large enough.\n\nEx. 3.3: Write a function named eulers_e that takes two inputs x and n, calculates \\[\n\\left(1+\\frac{x}{n}\\right)^{n}\n\\] and returns this value. Use your function to calculate eulers_e(1, 5) and store this value in the variable answer_33.\n\n\n### BEGIN SOLUTION\ndef eulers_e(x, n):\n    return (1 + x / n) ** n\n\nanswer_33 = eulers_e(1, 5) \n### END SOLUTION\n\n\n\nProblem 3.4 (OPTIONAL)\nThe inverse of the exponential is the logarithm. Like the exponential function, there are limit definitions of the logarithm. One of these is \\[\n\\log(x) = 2 \\cdot \\sum_{k=0}^{\\infty} \\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\n\\]\nwhere \\(\\sum_{k=0}^{\\infty}\\) signifies the sum of infinitely many elements, starting from \\(k=0\\). Each element in the sum takes the value \\(\\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\\) for some \\(k\\). As before, we must approximate this with a finite sum.\n\nEx. 3.4: Define another function called natural_logarithm which takes two inputs x and k_max. In the function body calculate \\[\n2 \\cdot \\sum_{k=0}^{k\\_max} \\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\n\\] and return this value.\n\n\nHint: to calculate the sum, first initialize a value total = 0, loop through \\(k\\in \\{0, 1, \\ldots, k\\_max\\}\\) and compute \\(\\frac{1}{2k+1} \\left( \\frac{x-1}{x+1} \\right)^{2k+1}\\). Add the computed value to your total in each step of the loop. After finalizing the loop you can then multiply the total by 2 and return the result.\n\n\n### BEGIN SOLUTION\ndef natural_logarithm(x, k_max):\n    return 2 * sum([1 / (2 * k + 1) * ((x - 1)/(x + 1)) ** (2 * k + 1) \n                    for k in range(k_max + 1)])\nprint(natural_logarithm(1,100))\n### END SOLUTION\n\n0.0\n\n\n\n\nProblem 3.5 (OPTIONAL)\nJust like numbers, strings and data types, python treats functions as an object. This means you can write functions, that take a function as input and functions that return functions after being executed. This is sometimes a useful tool to have when you need to add extra functionality to an already existing function, or if you need to write function factories.\n\nEx. 3.5: Write a function called exponentiate that takes one input named func. In the body of exponentiate define a nested function (i.e. a function within a function) called with_exp that takes two inputs x and k. The nested function should return func(e, k) where e = eulers_e(x, k). The outer function should return the nested function with_exp, i.e. write something like\n\ndef exponentiate(func):\n    def with_exp(x, k):\n        e = eulers_e(x, k)\n        value = #[FILL IN]\n        return value\n    return with_exp\n\nCall the exponentiate function on natural_logarithm and store the result in a new variable called logexp.\n\n\nHint: You will not get exactly the same result as you put in due to approximations and numerical accuracy.\n\n\n### BEGIN SOLUTION\ndef exponentiate(func):\n    def with_exp(x, k):\n        e = eulers_e(x, k)\n        value = func(e, k)\n        return value\n    return with_exp\n\nlogexp = exponentiate(natural_logarithm)\nprint(logexp(1, 100))\n### END SOLUTION\n\n0.9950330853168091"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#an-overview",
    "href": "exercises_html/2_exercise_sol.html#an-overview",
    "title": "Machine learning course for VIVE",
    "section": "An Overview",
    "text": "An Overview\nTabular data is like the table below. Each row is an observation which consist of two entries, one for each of the columns/fields, i.e. animal and day.\n\n\n\nindex\nAnimal\nDate\n\n\n\n\nObservation 1\nElk\nJuly 1, 2019\n\n\nObservation 2\nPig\nJuly 3, 2019\n\n\n\nWhat pandas provides is a smart way of structuring data. It has two fundamental data types, see below. These are essentially just container but come with a lot of extra functionality for structuring data and performing analysis.\n\nSeries: tabular data with a single column (field)\n\nakin to a vector in mathematics\nhas labelled columns (e.g. Animal and Date above) and named rows, called indices.\n\nDataFrame: tabular data that allows for more than one column (multiple fields)\n\nakin to a matrix in mathematics\n\n\nRun the code below to make your first pandas dataframe. Try to print it and explain the content it shows.\n\nimport pandas as pd\n\ndf1 = pd.DataFrame(data=[[1, 2],[3, 4],[5, 6],[7, 8]],\n                   index=['i', 'ii','iii','iv'],\n                   columns=['A', 'B'])\n\nThe code below makes a series from a list. We can see that it contains all the four fundamental data types!\n\nL = [1, 1.2, 'abc', True]\nser1 = pd.Series(L)\n\nNow you may ask yourself: why don’t we just use numpy?\nThere are many reasons. pandas is easier for loading, structuring and making simple analysis of tabular data. However, in many cases, if you are working with custom data or need to performing fast and complex array computations, then numpy is a better option. If you are interested see discussion here."
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#switching-among-python-numpy-and-pandas",
    "href": "exercises_html/2_exercise_sol.html#switching-among-python-numpy-and-pandas",
    "title": "Machine learning course for VIVE",
    "section": "Switching Among Python, Numpy and Pandas",
    "text": "Switching Among Python, Numpy and Pandas\nPandas dataframes can be thought of as numpy arrays with some additional stuff. Note that columns can have different datatypes!\nMost functions from numpy can be applied directly to Pandas. We can convert a DataFrame to a numpy array with values attribute:\n\ndf1.values\n\narray([[1, 2],\n       [3, 4],\n       [5, 6],\n       [7, 8]], dtype=int64)\n\n\nIn Python, we can describe it as a list of lists.\n\ndf1.values.tolist()\n\n[[1, 2], [3, 4], [5, 6], [7, 8]]\n\n\nBoth dataframes and series have indices which are both a blessing and a curse. These indices means that we can often convert a Series into a dictionary:\n\nser1.to_dict()\n\n{0: 1, 1: 1.2, 2: 'abc', 3: True}\n\n\nWARNING!: Series indices are NOT unique thus we may lose data if we convert to a dict which requires unique keys."
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#inspection",
    "href": "exercises_html/2_exercise_sol.html#inspection",
    "title": "Machine learning course for VIVE",
    "section": "Inspection",
    "text": "Inspection\nOften we want to see what our dataframe contains. This can be done by putting the dataframe at the end of our cell, then it will automatically be printed.\nThe example below consist of 100 rows, with 5 columns of random data. We see that putting the dataframe in the end prints the dataframe.\n\ndf2 = pd.DataFrame(data=np.random.rand(100, 5), \n                   columns=['A','B','C','D','E'])\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.291100\n      0.094683\n      0.550356\n      0.911622\n      0.374320\n    \n    \n      1\n      0.933523\n      0.830997\n      0.430150\n      0.235283\n      0.129003\n    \n    \n      2\n      0.900874\n      0.708393\n      0.950499\n      0.171770\n      0.503687\n    \n    \n      3\n      0.214144\n      0.735157\n      0.651842\n      0.580469\n      0.448282\n    \n    \n      4\n      0.756690\n      0.119340\n      0.269215\n      0.099179\n      0.411532\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      0.728482\n      0.232860\n      0.854766\n      0.784101\n      0.711444\n    \n    \n      96\n      0.706587\n      0.819365\n      0.090774\n      0.303287\n      0.224769\n    \n    \n      97\n      0.796380\n      0.783840\n      0.740566\n      0.747527\n      0.969443\n    \n    \n      98\n      0.433955\n      0.938853\n      0.932820\n      0.845110\n      0.583784\n    \n    \n      99\n      0.658342\n      0.699536\n      0.337664\n      0.424492\n      0.458236\n    \n  \n\n100 rows × 5 columns\n\n\n\nWe can also use head and the tail method that select respectively the first and last observations in a DataFrame. The code below prints the first four rows.\n\ndf3 = df2.head(n=4)\ndf3\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.291100\n      0.094683\n      0.550356\n      0.911622\n      0.374320\n    \n    \n      1\n      0.933523\n      0.830997\n      0.430150\n      0.235283\n      0.129003\n    \n    \n      2\n      0.900874\n      0.708393\n      0.950499\n      0.171770\n      0.503687\n    \n    \n      3\n      0.214144\n      0.735157\n      0.651842\n      0.580469\n      0.448282"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#input-output",
    "href": "exercises_html/2_exercise_sol.html#input-output",
    "title": "Machine learning course for VIVE",
    "section": "Input-output",
    "text": "Input-output\nWe can load and save dataframes from our computer or the internet. Try the code below to save our dataframe as a CSV file called my_data.csv. If you are unsure what a CSV file is then check the Wikipedia description.\n\ndf3.to_csv('my_data.csv')\n\nLoading data is just as easy. Some data sources are open and easy to collect data from. They do not require formatting as they come in a table format. The code below load a CSV file on school test data from NYC.\n\nmy_url = 'https://data.cityofnewyork.us/api/views/zt9s-n5aj/rows.csv'\nmy_df = pd.read_csv(my_url)\n\nmy_df.head(10)\n\n\n\n\n\n  \n    \n      \n      DBN\n      School Name\n      Number of Test Takers\n      Critical Reading Mean\n      Mathematics Mean\n      Writing Mean\n    \n  \n  \n    \n      0\n      01M292\n      Henry Street School for International Studies\n      31.0\n      391.0\n      425.0\n      385.0\n    \n    \n      1\n      01M448\n      University Neighborhood High School\n      60.0\n      394.0\n      419.0\n      387.0\n    \n    \n      2\n      01M450\n      East Side Community High School\n      69.0\n      418.0\n      431.0\n      402.0\n    \n    \n      3\n      01M458\n      SATELLITE ACADEMY FORSYTH ST\n      26.0\n      385.0\n      370.0\n      378.0\n    \n    \n      4\n      01M509\n      CMSP HIGH SCHOOL\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      5\n      01M515\n      Lower East Side Preparatory High School\n      154.0\n      314.0\n      532.0\n      314.0\n    \n    \n      6\n      01M539\n      New Explorations into Sci, Tech and Math HS\n      47.0\n      568.0\n      583.0\n      568.0\n    \n    \n      7\n      01M650\n      CASCADES HIGH SCHOOL\n      35.0\n      411.0\n      401.0\n      401.0\n    \n    \n      8\n      01M696\n      BARD HIGH SCHOOL EARLY COLLEGE\n      138.0\n      630.0\n      608.0\n      630.0\n    \n    \n      9\n      02M047\n      AMERICAN SIGN LANG ENG DUAL\n      11.0\n      405.0\n      415.0\n      385.0\n    \n  \n\n\n\n\n\nWorking with weather data\nWe will now work with a dataset regarding weather. Our source will be National Oceanic and Atmospheric Administration (NOAA) which have a global data collection going back a couple of centuries. This collection is called Global Historical Climatology Network (GHCN). The data contains daily weather recorded at the weather stations. A description of GHCN can be found here.\n\n\nProblem 4.1\n\nEx. 4.1: Use Pandas’ CSV reader to fetch daily data weather from 1863 for various stations - available somewhere on your common drive. If you cannot find it, it can also be found at this website.\nHint: you will need to give read_csv some keywords. Here are some suggestions - Specify the path, using either a string or through the pathlib module, see documentation (nice for interoperability between macOS + Windows and relative paths). - for compressed files you may need to specify the keyword compression when calling the .read_csv method. - header can be specified as the CSV has no column names.\n\n\nimport pandas as pd\n\n\n### BEGIN SOLUTION\n# using online url\npath = \"https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/1863.csv.gz\"\n\n# ASSUMING data is in a folder called 'data':\n\n# using string \n#path = 'data/1863.csv.gz'\n\n# using pathlib\n#from pathlib import Path\n#cwd = Path.cwd()\n#path = cwd / 'data' / '1863.csv.gz'\n\ndf_weather = pd.read_csv(\n    path,\n    compression='gzip', # decompress gzip\n    header=None # use no header information from the csv\n) \n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#selecting-rows-and-columns",
    "href": "exercises_html/2_exercise_sol.html#selecting-rows-and-columns",
    "title": "Machine learning course for VIVE",
    "section": "Selecting Rows and Columns",
    "text": "Selecting Rows and Columns\nIn pandas there are two canonical ways of accessing subsets of a dataframe. - The iloc attribute: access rows and columns using integer indices (like a list). - The loc attribute: access rows and columns using immutable keys, e.g. numbers, strings (like a dictionary).\nIn what follows we will describe some different way of selection using .iloc and .loc as well as a simpler way of simply accesing the dataframe using []. The different ways are meant to give you an overview.\n\nUsing list of keys/indices\nBelow is an example of using the iloc attribute to select specific rows:\n\ndf1 # show df1 before indexing it with .iloc[]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      i\n      1\n      2\n    \n    \n      ii\n      3\n      4\n    \n    \n      iii\n      5\n      6\n    \n    \n      iv\n      7\n      8\n    \n  \n\n\n\n\n\nmy_irows = [0, 3]\ndf1.iloc[my_irows]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      i\n      1\n      2\n    \n    \n      iv\n      7\n      8\n    \n  \n\n\n\n\nWe can select columns and rows simultaneously. Below is an example of using the loc attribute, which does that:\n\nmy_rows = ['i', 'iii']\nmy_cols = ['A']\ndf1.loc[my_rows, my_cols]\n\n\n\n\n\n  \n    \n      \n      A\n    \n  \n  \n    \n      i\n      1\n    \n    \n      iii\n      5\n    \n  \n\n\n\n\n\n\nUsing thresholds\nWe can also use iloc and loc for selecting rows and/or columns below or above some treshold, see below. Note that whether or not the : is on front determines whether it is above or below.\n\ndf2.iloc[:3, :4]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.291100\n      0.094683\n      0.550356\n      0.911622\n    \n    \n      1\n      0.933523\n      0.830997\n      0.430150\n      0.235283\n    \n    \n      2\n      0.900874\n      0.708393\n      0.950499\n      0.171770\n    \n  \n\n\n\n\n\n\nUsing boolean data\nIf we provide the dataframe with a boolean, it will select rows (also works with iloc and loc). We will see soon that this is an extremely useful way of selecting certain rows.\n\ndf3[[True, False, False, True]]\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0.291100\n      0.094683\n      0.550356\n      0.911622\n      0.374320\n    \n    \n      3\n      0.214144\n      0.735157\n      0.651842\n      0.580469\n      0.448282\n    \n  \n\n\n\n\n\n\nSelecting columns\nOften we need to select specific columns. If we provide the dataframe with a list of column names it will make a dataframe keep only these columns:\n\ndf3[['B', 'D']]\n\n\n\n\n\n  \n    \n      \n      B\n      D\n    \n  \n  \n    \n      0\n      0.094683\n      0.911622\n    \n    \n      1\n      0.830997\n      0.235283\n    \n    \n      2\n      0.708393\n      0.171770\n    \n    \n      3\n      0.735157\n      0.580469\n    \n  \n\n\n\n\n\n\nProblem 4.2\n\nEx 4.2: Select the four left-most columns which contain: station identifier, data, observation type, observation value. Rename them as ‘station’, ‘datetime’, ‘obs_type’, ‘obs_value’.\n\n\nHint: Renaming can be done with df.columns = cols where cols is a list of column names.\n\n\n### BEGIN SOLUTION\ndf_weather = df_weather.iloc[:, :4] # select only first four columns\n\ncolumn_names = ['station', 'datetime', 'obs_type', 'obs_value']\ndf_weather.columns = column_names # set column names\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#basic-operations",
    "href": "exercises_html/2_exercise_sol.html#basic-operations",
    "title": "Machine learning course for VIVE",
    "section": "Basic Operations",
    "text": "Basic Operations\nHow do we perform elementary operations like we learned for basic Python? E.g. numeric operations such as summation (+) or logical operations such as greater than (>). Actually we are in luck - they are exactly the same.\nLet’s see how it works for numeric data using a numpy array (works the same way as Pandas).\n\nmy_arr1 = np.array([2, 3, 2, 1, 1])\nmy_arr2 = my_arr1 ** 2\nmy_arr2\n\narray([4, 9, 4, 1, 1])\n\n\nCan we do the same with two vectors? Yes, we can also do elementwise addition, multiplication, subtractions etc. of series. Example:\n\nmy_arr1 + my_arr2\n\narray([ 6, 12,  6,  2,  2])"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#changing-and-copying-data",
    "href": "exercises_html/2_exercise_sol.html#changing-and-copying-data",
    "title": "Machine learning course for VIVE",
    "section": "Changing and Copying Data",
    "text": "Changing and Copying Data\nEverything in the dataframe can be changed. For instance, we can also update our dataframe with new values, e.g. by making new variables or overwriting existing ones. In the example below we add a new column to add a DataFrame.\n\ndf2['F'] = df2['A'] > df2['D']\ndf2.head(10)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n      F\n    \n  \n  \n    \n      0\n      0.291100\n      0.094683\n      0.550356\n      0.911622\n      0.374320\n      False\n    \n    \n      1\n      0.933523\n      0.830997\n      0.430150\n      0.235283\n      0.129003\n      True\n    \n    \n      2\n      0.900874\n      0.708393\n      0.950499\n      0.171770\n      0.503687\n      True\n    \n    \n      3\n      0.214144\n      0.735157\n      0.651842\n      0.580469\n      0.448282\n      False\n    \n    \n      4\n      0.756690\n      0.119340\n      0.269215\n      0.099179\n      0.411532\n      True\n    \n    \n      5\n      0.634309\n      0.958614\n      0.330676\n      0.454304\n      0.098996\n      True\n    \n    \n      6\n      0.327120\n      0.263946\n      0.884487\n      0.238092\n      0.283622\n      True\n    \n    \n      7\n      0.180478\n      0.433104\n      0.719118\n      0.188784\n      0.674121\n      False\n    \n    \n      8\n      0.645979\n      0.667443\n      0.978808\n      0.531604\n      0.241179\n      True\n    \n    \n      9\n      0.940160\n      0.744014\n      0.657913\n      0.348178\n      0.940021\n      True\n    \n  \n\n\n\n\nWARNING!: If you work on a subset of data from another dataframe, then this dataframe is what is known as a view! Therefore, all changes made in the view will also be made in the original version.\nIn the example below, we try to change the dataframe df2 which is a view of df3, and we get a warning. Thus, changes to df3 also happen in df2. Notice that we can also use loc for changing the data.\n\ndf3.loc[:,'D'] = df3['A'] - df3['E']\nprint(df2['D'].head(3), '\\n')\nprint(df3['D'].head(3))\n\n0   -0.083219\n1    0.804520\n2    0.397187\nName: D, dtype: float64 \n\n0   -0.083219\n1    0.804520\n2    0.397187\nName: D, dtype: float64\n\n\nC:\\Users\\wkg579\\AppData\\Local\\Temp\\ipykernel_18024\\2462267356.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df3.loc[:,'D'] = df3['A'] - df3['E']\n\n\nTo avoid the problem of having a view, we can instead copy the data as in the example below. Try to verify that if you change things in df4 things do not change in df2.\n\ndf4 = df2.copy()\n\n\n# Verify that the code from above doesn't throw the same \"SettingWithCopyWarning\" \n# when using the copied dataframe, df4, instead of df3.\ndf4.loc[:, 'D'] = df4['A'] - df4['E']\n\n\nProblem 4.3\n\nEx. 4.3: Further, select the subset of data for the station UK000056225 and only observations for maximal temperature. Make a copy of the DataFrame and store this in the variable df_select. Explain in a one or two sentences how copying works. Write your answer in a multi line comment like \"\"\" Your answer here \"\"\".\n\n\nHint: The & operator works elementwise on boolean series (like and in core python). This allows to combine conditions for selections.\n\n\n### BEGIN SOLUTION\nselect_stat = df_weather.station == 'UK000056225' # boolean: first weather station\nselect_tmax = df_weather.obs_type == 'TMAX' # boolean: maximal temp.\n\nselect_rows = select_stat & select_tmax # row selection - require both conditions\n\ndf_select = df_weather[select_rows].copy() # apply selection and copy\n\nexplanation = \"\"\"Copying of the dataframe breaks the dependency with original DataFrame `df_weather`.\nIf dependency is not broken, then changing values in one of the two dataframes \nwould imply changes in the other.\"\"\"\nprint(explanation)\n### END SOLUTION\n\nCopying of the dataframe breaks the dependency with original DataFrame `df_weather`.\nIf dependency is not broken, then changing values in one of the two dataframes \nwould imply changes in the other.\n\n\n\n\nProblem 4.4\n\nEx 4.4: Make sure that max temperature is correctly formated (how many decimals should we add? one? Look through this .txt file for an answer https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt). Make a new column called TMAX_F where you have converted the temperature variables to Fahrenheit.\n\n\nHint: Conversion is \\(F = 32 + 1.8*C\\) where \\(F\\) is Fahrenheit and \\(C\\) is Celsius.\n\n\n### BEGIN SOLUTION\n# In the readme.txt file downloaded from the link given in the exercise text,\n# it can be seen, in the section 'III. FORMAT OF DATA FILES', that \n# TMAX = Maximum temperature (tenths of degrees C). \n# Therefore, we convert to degrees celcius by dividing by 10. \ndf_select['obs_value'] = df_select['obs_value'] / 10 \ndf_select['TMAX_F'] = 32 + 1.8 * df_select['obs_value']\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/2_exercise_sol.html#changing-and-rearranging-indices",
    "href": "exercises_html/2_exercise_sol.html#changing-and-rearranging-indices",
    "title": "Machine learning course for VIVE",
    "section": "Changing and Rearranging Indices",
    "text": "Changing and Rearranging Indices\nIn addition to replacing values of our data, we can also rearrange the order of variables and rows as well as make new ones. We have already seen how to change column names but we can also reset the index, as seen below. Alternatively, we can set our own custom index using set_index, with temporal data etc. which provides the DataFrame with new functionality.\n\ndf1_new_index = df1.reset_index(drop=True)\ndf1_new_index\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      5\n      6\n    \n    \n      3\n      7\n      8\n    \n  \n\n\n\n\nA powerful tool for re-organizing the data is to sort the data. That is, we can re-organize rows (or columns) such that they are ascending or descending according to one or more columns.\n\ndf3_sorted = df3.sort_values(by=['A','B'], ascending=True)\ndf3_sorted\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      3\n      0.214144\n      0.735157\n      0.651842\n      -0.234138\n      0.448282\n    \n    \n      0\n      0.291100\n      0.094683\n      0.550356\n      -0.083219\n      0.374320\n    \n    \n      2\n      0.900874\n      0.708393\n      0.950499\n      0.397187\n      0.503687\n    \n    \n      1\n      0.933523\n      0.830997\n      0.430150\n      0.804520\n      0.129003\n    \n  \n\n\n\n\n\nProblem 4.5\n\nEx 4.5: Inspect the indices in df_select. Are they following the sequence of natural numbers, 0,1,2,…? If not, reset the index and make sure to drop the old.\n\n\n### BEGIN SOLUTION\ndf_select = df_select.reset_index(drop=True)\n### END SOLUTION\n\n\n\nProblem 4.6\n\nEx 4.6: Make a new DataFrame df_sorted where you have sorted by the maximum temperature. What is the date for the first and last observations?\n\n\n### BEGIN SOLUTION\ndf_sorted = df_select.sort_values(by=['obs_value'])\nprint(\n    f\"Date for the min temp: {df_sorted['datetime'].iloc[0]}\", \n    f\"Date for the max temp: {df_sorted['datetime'].iloc[-1]}\",\n    sep=\"\\n\"\n)\n### END SOLUTION\n\nDate for the min temp: 18631231\nDate for the max temp: 18630714"
  },
  {
    "objectID": "exercises_html/3_exercise.html",
    "href": "exercises_html/3_exercise.html",
    "title": "Machine learning course for VIVE",
    "section": "",
    "text": "In this exercise set, you will be introduced to cross validation to perform model and hyperparameterselection, allowing us to tackle over and underfitting. The models used will be regularized linear models, where we will also look at how the two canonical models, the Ridge and Lasso, compare to eachother.\nThe structure of this notebook is as follows: 1. The holdout method 2. Cross validation and pipelines\n\n\nFirst, we need to import our standard stuff. Notice that we are not interested in seeing the convergence warning in scikit-learn, so we suppress them for now.\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \n\n%matplotlib inline"
  },
  {
    "objectID": "exercises_html/3_exercise.html#k-fold-cross-validation",
    "href": "exercises_html/3_exercise.html#k-fold-cross-validation",
    "title": "Machine learning course for VIVE",
    "section": "K fold cross validation",
    "text": "K fold cross validation\nThe simple validation procedure that we used above has one disadvantage: it only uses parts of the development data for validation. To avoid this issue, we can utilize K fold cross validation.\nWhen we want to optimize over both normal parameters and hyperparameters, we do this using nested loops (two-layered cross validation). In the outer loop, we vary the hyperparameters, and then in the inner loop, we do cross validation for the model with the specific selection of hyperparameters. This way, we can find the model with the lowest mean MSE.\n\n(OPTIONAL) Ex. 2.3: Run a Lasso regression using the Pipeline from Ex 2.2. In the outer loop, search through the lambdas specified below. In the inner loop, make 5 fold cross validation on the selected model and store the average MSE for each fold. Which lambda, from the selection below, gives the lowest test MSE? python  lambdas =  np.logspace(-4, 4, 10) Hint: KFold in sklearn.model_selection may be useful.\n\nWhen you have more than one hyperparameter, you will want to fit the model to all the possible combinations of hyperparameters. This is done in an approch called Grid Search, which is implementet in sklearn.model_selection as GridSearchCV.\nHowever, this is also very useful when you only have one hyperparameter, as it removes a lot of the boilerplate code.\n\nEx. 2.4: To get to know Grid Search, we want to implement it in one dimension. Using GridSearchCV, implement the Lasso pipeline, with the same lambdas as before (lambdas =  np.logspace(-4, 4, 10)), 5-fold CV and (negative) mean squared error as the scoring variable. Which value of \\(\\lambda\\) gives the lowest test error?\n\n\n(OPTIONAL) Ex. 2.5 Now set lambdas =  np.logspace(-4, 4, 100), and repeat the previous exercise now with RandomizedSearchCV with n_iter=12. What’s the difference between the two gridsearches?\n\nWe will now use the search functions with more than one hyperparameter, displaying their flexibility and power.\nTo do this, we need a model with more than one hyperparameter. The Elastic Net is one such example, which has two hyperparameters. The first hyperparametes determines how much to regularize, and the second determins how to weigh between Lasso and Ridge regularization.\n\n(OPTIONAL) Ex. 2.6 Implement an Elastic Net using RandomizedSearchCV with n_iter=10 and the previous lambda values. > Hints: - Try using np.linspace to create linearly spaced hyperparameters. - Try importing ElasticNet from sklearn.linear_model. - The documentation for ElasticNet has information on the hyperparameters and their exact names."
  },
  {
    "objectID": "exercises_html/3_exercise.html#tools-for-model-selection",
    "href": "exercises_html/3_exercise.html#tools-for-model-selection",
    "title": "Machine learning course for VIVE",
    "section": "Tools for model selection",
    "text": "Tools for model selection\nBelow we review two useful tools for performing model selection. The first tool, the learning curve, can be used to assess whether there is over- and underfitting.\n\n(OPTIONAL) Ex. 2.7 Learning curves\nCreate a learning curve using 5 fold cross validation and the \\(\\lambda\\) found in exercise 2.4. What does it tell you about over- and underfitting?\nHint: Try importing learning_curve from sklearn.model_selection.\n\n\n(OPTIONAL) Ex.2.8: Automated Cross Validation in one dimension\nWhen you are doing cross validation with one hyperparameter, you can automate the process by using validation_curve from sklearn.model_selection and easily plot validation curves afterwards. Use this function to search through the values of lambdas, and find the value of lambda, which gives the lowest test error.\n\n\n(OPTIONAL) Ex. 2.9: Plot the average MSE-test and MSE-train (validation curve) against the different values of lambda. Does this differ from the one in exercise 1.6? If yes, why?\nHints: - Use logarithmic axes, and lambda as index - Have you done the same sample splitting in this and exercise 1.6?"
  },
  {
    "objectID": "exercises_html/3_exercise_sol.html",
    "href": "exercises_html/3_exercise_sol.html",
    "title": "Machine learning course for VIVE",
    "section": "",
    "text": "In this exercise set, you will be introduced to cross validation to perform model and hyperparameterselection, allowing us to tackle over and underfitting. The models used will be regularized linear models, where we will also look at how the two canonical models, the Ridge and Lasso, compare to eachother.\nThe structure of this notebook is as follows: 1. The holdout method 2. Cross validation and pipelines\n\n\nFirst, we need to import our standard stuff. Notice that we are not interested in seeing the convergence warning in scikit-learn, so we suppress them for now.\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \n\n%matplotlib inline"
  },
  {
    "objectID": "exercises_html/3_exercise_sol.html#k-fold-cross-validation",
    "href": "exercises_html/3_exercise_sol.html#k-fold-cross-validation",
    "title": "Machine learning course for VIVE",
    "section": "K fold cross validation",
    "text": "K fold cross validation\nThe simple validation procedure that we used above has one disadvantage: it only uses parts of the development data for validation. To avoid this issue, we can utilize K fold cross validation.\nWhen we want to optimize over both normal parameters and hyperparameters, we do this using nested loops (two-layered cross validation). In the outer loop, we vary the hyperparameters, and then in the inner loop, we do cross validation for the model with the specific selection of hyperparameters. This way, we can find the model with the lowest mean MSE.\n\n(OPTIONAL) Ex. 2.3: Run a Lasso regression using the Pipeline from Ex 2.2. In the outer loop, search through the lambdas specified below. In the inner loop, make 5 fold cross validation on the selected model and store the average MSE for each fold. Which lambda, from the selection below, gives the lowest test MSE? python  lambdas =  np.logspace(-4, 4, 10) Hint: KFold in sklearn.model_selection may be useful.\n\n\n### BEGIN SOLUTION\nfrom sklearn.model_selection import KFold\n\nlambdas =  np.logspace(-4, 4, 10)\n\nkfolds = KFold(n_splits=5)\nmses = []\n\nfor lambda_ in lambdas:\n\n    pipe_lasso = Pipeline([\n            ('pol_features', PolynomialFeatures(degree=3, include_bias=False)),                           \n            ('scaler', StandardScaler()),\n            ('lasso', Lasso(alpha=lambda_, random_state=1))\n            ]\n        )\n        \n    mses_test = []\n    mses_train = []\n\n    for train_idx, val_idx in kfolds.split(X_dev, y_dev):\n        X_train, y_train = X_dev.iloc[train_idx], y_dev[train_idx]\n        X_val, y_val = X_dev.iloc[val_idx], y_dev[val_idx]\n\n        pipe_lasso.fit(X_train, y_train)\n\n        mses_train.append(mse(pipe_lasso.predict(X_train), y_train))\n        mses_test.append(mse(pipe_lasso.predict(X_val), y_val))\n\n    mses.append([np.mean(mses_train), np.mean(mses_test), lambda_])\n\n# Create df with MSE values\ndf_mses = pd.DataFrame(mses, columns=[\"MSE_train\", \"MSE_test\", \"lambda\"])\n\n# Index of the lambda that gives the lowest MSE_test in the dataframe\nidx_optimal_lambda = df_mses.idxmin()[\"MSE_test\"]\nlambda_opt_test = df_mses.loc[idx_optimal_lambda][\"lambda\"]\nopt_test_mse = df_mses.loc[idx_optimal_lambda][\"MSE_test\"]\nprint(\n    f\"Lowest test MSE equal to {opt_test_mse:.4f} is\"\n    f\" achieved with lambda = {lambda_opt_test:.5f}.\"\n)\n\nLowest test MSE equal to 0.5939 is achieved with lambda = 0.04642.\n\n\nWhen you have more than one hyperparameter, you will want to fit the model to all the possible combinations of hyperparameters. This is done in an approch called Grid Search, which is implementet in sklearn.model_selection as GridSearchCV.\nHowever, this is also very useful when you only have one hyperparameter, as it removes a lot of the boilerplate code.\n\nEx. 2.4: To get to know Grid Search, we want to implement it in one dimension. Using GridSearchCV, implement the Lasso pipeline, with the same lambdas as before (lambdas =  np.logspace(-4, 4, 10)), 5-fold CV and (negative) mean squared error as the scoring variable. Which value of \\(\\lambda\\) gives the lowest test error?\n\n\n### BEGIN SOLUTION\n\nfrom sklearn.model_selection import GridSearchCV\n\ngs = GridSearchCV(estimator=pipe_lasso, \n                  param_grid=[{'lasso__alpha':lambdas}], \n                  scoring='neg_mean_squared_error', \n                  cv=5, \n                  n_jobs=-1)\n\ngs = gs.fit(X_dev, y_dev)\nprint(gs.best_params_)\n\nlasso_best_lambda = gs.best_params_['lasso__alpha']\n\n### END SOLUTION\n\n{'lasso__alpha': 0.046415888336127774}\n\n\n\n(OPTIONAL) Ex. 2.5 Now set lambdas =  np.logspace(-4, 4, 100), and repeat the previous exercise now with RandomizedSearchCV with n_iter=12. What’s the difference between the two gridsearches?\n\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# BEGIN SOLUTION\n\nlambdas_new = np.logspace(-4, 4, 100)\n\ngs = RandomizedSearchCV(estimator = pipe_lasso,\n                                param_distributions = [{\"lasso__alpha\": lambdas_new}], \n                                cv = 10, \n                                scoring = \"neg_mean_squared_error\",\n                                n_iter = 12,\n                                random_state=1)\n\ngs.fit(X_dev,y_dev)\n\nprint(gs.best_params_)\n\n### END SOLUTION\n\n{'lasso__alpha': 0.04641588833612782}\n\n\nWe will now use the search functions with more than one hyperparameter, displaying their flexibility and power.\nTo do this, we need a model with more than one hyperparameter. The Elastic Net is one such example, which has two hyperparameters. The first hyperparametes determines how much to regularize, and the second determins how to weigh between Lasso and Ridge regularization.\n\n(OPTIONAL) Ex. 2.6 Implement an Elastic Net using RandomizedSearchCV with n_iter=10 and the previous lambda values. > Hints: - Try using np.linspace to create linearly spaced hyperparameters. - Try importing ElasticNet from sklearn.linear_model. - The documentation for ElasticNet has information on the hyperparameters and their exact names.\n\n\n### BEGIN SOLUTION\nfrom sklearn.linear_model import ElasticNet\n\npipe_elastic = Pipeline([\n    ('pol_features', PolynomialFeatures(degree=3, include_bias=False)),                           \n    ('scaler', StandardScaler()),\n    ('elasticnet', ElasticNet(random_state=1))\n    ]\n    )\n\nlambdas_new = np.logspace(-4, 4, 100)\nl1_ratio = np.linspace(0,1, 10)\n\ngs = RandomizedSearchCV(estimator = pipe_elastic,\n                                param_distributions = {\"elasticnet__alpha\": lambdas_new,\n                                                    \"elasticnet__l1_ratio\": l1_ratio}\n                                                    , \n                                cv = 10, \n                                scoring = \"neg_mean_squared_error\",\n                                n_iter = 10,\n                                random_state=1)\n\ngs.fit(X_dev,y_dev)\n\nprint(gs.best_params_)\n\ngs.score(X_test,y_test)\n### END SOLUTION\n\n{'elasticnet__l1_ratio': 0.5555555555555556, 'elasticnet__alpha': 0.007220809018385471}\n\n\n-29.681336441916752"
  },
  {
    "objectID": "exercises_html/3_exercise_sol.html#tools-for-model-selection",
    "href": "exercises_html/3_exercise_sol.html#tools-for-model-selection",
    "title": "Machine learning course for VIVE",
    "section": "Tools for model selection",
    "text": "Tools for model selection\nBelow we review two useful tools for performing model selection. The first tool, the learning curve, can be used to assess whether there is over- and underfitting.\n\n(OPTIONAL) Ex. 2.7 Learning curves\nCreate a learning curve using 5 fold cross validation and the \\(\\lambda\\) found in exercise 2.4. What does it tell you about over- and underfitting?\nHint: Try importing learning_curve from sklearn.model_selection.\n\n\n### BEGIN SOLUTION\n\nfrom sklearn.model_selection import learning_curve\n\npipe_lasso = Pipeline([\n            ('pol_features', PolynomialFeatures(degree=3, include_bias=False)),                           \n            ('scaler', StandardScaler()),\n            ('lasso', Lasso(alpha=lasso_best_lambda, random_state=1))\n            ]\n        )\n\nlambdas =  np.logspace(-4, 4, 10)\n\nn_obs, train_scores, test_scores = \\\n    learning_curve(estimator=pipe_lasso,\n                     X=X_dev,\n                     y=y_dev,\n                     train_sizes=np.linspace(0.1,1,10),\n                     scoring='neg_mean_squared_error',# scoring='neg_mean_squared_error',                 \n                     cv=5)\n\nmean_values = pd.concat({'train': pd.DataFrame(-train_scores).mean(1), \n                         'test': pd.DataFrame(-test_scores).mean(1), \n                         'n_obs': pd.DataFrame(n_obs).mean(1)}, axis =1)\n\npd.concat({'train': pd.DataFrame(-train_scores).mean(1), \n           'test': pd.DataFrame(-test_scores).mean(1)},\n           axis=1)\\\n    .pipe(np.sqrt)\\\n    .set_index(pd.Index(n_obs, name='n_obs'))\\\n    .plot(logy=True)\n\nplt.show()\n\n# As the train and validation mean squared error stabilize and have a relatively small gap by the end, we have a well fit model \n### END SOLUTION\n\n\n\n\n\n(OPTIONAL) Ex.2.8: Automated Cross Validation in one dimension\nWhen you are doing cross validation with one hyperparameter, you can automate the process by using validation_curve from sklearn.model_selection and easily plot validation curves afterwards. Use this function to search through the values of lambdas, and find the value of lambda, which gives the lowest test error.\n\n\n### BEGIN SOLUTION\n\nfrom sklearn.model_selection import validation_curve\n\npipe_lasso = Pipeline([\n            ('pol_features', PolynomialFeatures(degree=3, include_bias=False)),                           \n            ('scaler', StandardScaler()),\n            ('lasso', Lasso(random_state=1))\n            ]\n        )\n\nlambdas =  np.logspace(-4, 4, 10)\n\ntrain_scores, test_scores = \\\n    validation_curve(estimator=pipe_lasso,\n                     X=X_dev,\n                     y=y_dev,\n                     param_name='lasso__alpha',\n                     param_range=lambdas,\n                     scoring='neg_mean_squared_error',              \n                     cv=5)\n\nmean_values = pd.concat({'train': pd.DataFrame(-train_scores).mean(1), \n                         'test': pd.DataFrame(-test_scores).mean(1), \n                         'lambda': pd.DataFrame(lambdas).mean(1)}, axis =1)\n\nmean_values\n### END SOLUTION\n\n\n\n\n\n  \n    \n      \n      train\n      test\n      lambda\n    \n  \n  \n    \n      0\n      0.400460\n      41.162396\n      0.000100\n    \n    \n      1\n      0.412454\n      2.015578\n      0.000774\n    \n    \n      2\n      0.455627\n      0.838400\n      0.005995\n    \n    \n      3\n      0.585684\n      0.593914\n      0.046416\n    \n    \n      4\n      0.811365\n      0.812094\n      0.359381\n    \n    \n      5\n      1.323110\n      1.323249\n      2.782559\n    \n    \n      6\n      1.323110\n      1.323249\n      21.544347\n    \n    \n      7\n      1.323110\n      1.323249\n      166.810054\n    \n    \n      8\n      1.323110\n      1.323249\n      1291.549665\n    \n    \n      9\n      1.323110\n      1.323249\n      10000.000000\n    \n  \n\n\n\n\n\n(OPTIONAL) Ex. 2.9: Plot the average MSE-test and MSE-train (validation curve) against the different values of lambda. Does this differ from the one in exercise 1.6? If yes, why?\nHints: - Use logarithmic axes, and lambda as index - Have you done the same sample splitting in this and exercise 1.6?\n\n\n### BEGIN SOLUTION\n\nfrom sklearn.metrics import mean_squared_error as mse\n\n# plot curves\npd.concat({'train': pd.DataFrame(-train_scores).mean(1), \n           'test': pd.DataFrame(-test_scores).mean(1)},\n           axis=1)\\\n    .pipe(np.sqrt)\\\n    .set_index(pd.Index(lambdas, name='lambda'))\\\n    .plot(logx=True, logy=True)\n\nplt.show()\n\n# It does differ for two reasons:\n# 1) this implementation uses 5 fold cross validation, whereas exercise 1.6 used only holdout\n# 2) In 1.6 we use the full train/development dataset to train on and plot out of sample using the test dataset. \n# This cannot be used for model selection, as we must NEVER use the test set for model selection.\n# In this exercise, we use cross validation to split the dataset into train and validation sets.\n# This allows us to do model selection without using the test set.\n### END SOLUTION"
  },
  {
    "objectID": "exercises_html/4_exercise.html",
    "href": "exercises_html/4_exercise.html",
    "title": "Machine learning course for VIVE",
    "section": "",
    "text": "In this exercise set, we will mainly be looking at different supervised learning algorithms, both tinkering around with them and seeing how the models perform for a given dataset. We will look at:\n\nLogistic regression\nDecision tree\nEnsemble methods\n\nRandom Forest\nAdaBoost\n\nNeural network\n\nIf you in general need more information about models or how to tune their hyperparameters, try looking up the documentation or googling hyperparameter tuning + model_name\nThroughout your career, you’ve probably worked with many problems. Some problems can easily be formulated as regression problem, whereas others are easily formulated as a classification problem.\n\nExercise 1.1\nName three different problems which you’ve worked with where the outcome of interest was:\n\nContinuous (regression)\nCategorical (classification)\n\nHave you encountered problems where the outcome of interest could be both continuous and categorical? Would being able to predict these outcomes of interest be valuable?\n\nFor this session, I invite you to use a dataset of your own, as different models work best for different problems: - This can be either a regression problem or a classification problem. - Feel free to preprocess in another program and export it as a csv file or another format of your choosing\nThe exercises are designed with a classification problem in mind, but all exercises except the ones about confusion matrices can be exchanged for regression problems by changin from a Classifier to a Regressor model.\nThe dataset I’ve decided upon is a dataset regarding classification of high income people, namely the Census Income Data Set from the UCI Machine Learning Repository. I’ve reduced the amount of features and sample size, as well as done a little bit of cleaning, from the full sample to reduce computation time. All the categorical features are one-hot encoded.\n\n# Suppress convergencewarnings if they appear\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n\n# Actual code to load\nimport pandas as pd\n\ndf = pd.read_csv('adult_preprocessed.csv')\ndf.describe()\n\n\nExercise 1.2\nWhat column in the DataFrame is the target of interest? Subset this as a Series called y, and the rest of the columns as a DataFrame called X\n\nHints:\ny = df['column_name'] subsets a column as a Series.\nX = df.drop(columns='column_name') drops a column in a dataframe\n\n\n\nExercise 1.3\nAs a first step, you should split the data into a development and test set. Make a development and test split with 80% of the data in the development set. Name them X_dev, X_test, y_dev and y_test\n\nHints:\nTry importing train_test_split from sklearn.model_selection"
  },
  {
    "objectID": "exercises_html/4_exercise.html#random-forest-bagging",
    "href": "exercises_html/4_exercise.html#random-forest-bagging",
    "title": "Machine learning course for VIVE",
    "section": "Random Forest (Bagging)",
    "text": "Random Forest (Bagging)\n\nExercise 3.1\nThe Random Forest has all the same hyperparameters as the decision tree, but also a few new. For each point below, explain what the hype parameter pertaining to sklearn.ensemble.RandomForestClassifier controls, and how setting it either too low or too high (or True/False) might hurt model performance: 1. n_estimators 2. max_depth 3. max_features 4. bootstrap\n\n\nExercise 3.2\nFor n_estimators > 1, how should one set the hyperparameters max_features and bootstrap so that all the trees in the ensemble end up identical?\n\n\nExercise 3.3\nCreate a validation plot with values of n_estimators. Use the values np.unique(np.logspace(0, 3, 25).astype(int)). How does it influence the train and validation scores?\n\n\nExercise 3.4\nWhat does the max_features parameter in a Random Forest do? Does the model overfit more or less if you increase this value?\nCreate a validation plot with values of max_features. Use the values np.arange(0.1, 1.01, 0.1). Does it influence the train and validation scores?\n\n\nExercise 3.5 (OPTIONAL)\nTo find the best hyperparamter values, implement a randomized search (RandomizedSearchCV) using the previous hyperparameter ranges, including the decision tree section. Use n_iter = 10. If your model takes too long to run, you can change this parameter – should you increase it or lower it to reduce running time? What are the best hyperparameters? How does the model perform on the test set? > > Hints: > > Look at exercise 2.6 from exercise session 3 for inspiration"
  },
  {
    "objectID": "exercises_html/4_exercise.html#adaboost-boosting",
    "href": "exercises_html/4_exercise.html#adaboost-boosting",
    "title": "Machine learning course for VIVE",
    "section": "AdaBoost (Boosting)",
    "text": "AdaBoost (Boosting)\n\nExercise 4.1\nWhat does the n_estimators parameter in a AdaBoost do? Does the model overfit more or less if you increase this value?\nCreate a validation plot with values of n_estimators. Use the values [int(x) for x in np.linspace(start = 1, stop = 500, num = 10)] > > Hints: > > Try importing AdaBoostClassifier from sklearn.ensemble\n\n\nExercise 4.2\nAs AdaBoost is a boosting algorithm, it is designed to use weak learners. What does this imply for the hyperparameter space you should search over?\n\n\nExercise 4.3 (OPTIONAL)\nIterate over the hyperparameter grid given below using RandomizedSearchCV with n_iter = 10. Are there any new hyperparameters that you haven’t seen before? Consider whether you are getting any corner solutions? What does this imply for your hyperparameter search?\nNote how I specify hyperparameters in the decision tree using __ twice, first to access base_estimator and then the base estimators hyperparameters.\n\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\npipeline = Pipeline([\n    ('adaboost', AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n])\n\n\nparam_grid= [{\n    'adaboost__n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 4)],\n    'adaboost__learning_rate': [0.01, 0.1, 0.5, 1],\n    'adaboost__base_estimator__max_depth': [1, 5, 9],\n    'adaboost__base_estimator__min_samples_split': [2, 5, 9],\n    'adaboost__base_estimator__min_samples_leaf': [1, 3, 5],\n    'adaboost__base_estimator__max_leaf_nodes': [2, 5, 9],\n    } ]"
  },
  {
    "objectID": "exercises_html/4_exercise.html#gradient-boosting",
    "href": "exercises_html/4_exercise.html#gradient-boosting",
    "title": "Machine learning course for VIVE",
    "section": "Gradient Boosting",
    "text": "Gradient Boosting\nAs a small aside, there exists a subset of boosting models called Gradient Boosting models. These models are very powerful, and you should be aware that they exist. In essence, instead of changing weights of samples, they are trained to minimize the residual.\nOne example from sklearn is GradientBoostingClassifier, see documentation here and HistGradientBoostingClassifier, see documentation here, which also have Regressor counterparts.\nThe perhaps most popular is XGBoost. It is not implemented in sklearn, but it uses the same interface, so the process is exactly the same with fit and predict. See the documentation here. The source is Chen, T., & Guestrin, C. (2016, August). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (pp. 785-794).\nOther boosting algorithms are LightGBM for efficient training and CatBoost for many categorical features."
  },
  {
    "objectID": "exercises_html/4_exercise.html#a-visual-inspection-of-neural-networks",
    "href": "exercises_html/4_exercise.html#a-visual-inspection-of-neural-networks",
    "title": "Machine learning course for VIVE",
    "section": "A visual inspection of neural networks",
    "text": "A visual inspection of neural networks\nInstead of diving into code, it’s more important that our intuition about what neural networks are doing is as good as possible. The best (and most fun) way to do that is to play around and with things a bit, so go familiarize yourself with the Tensorflow Playground, slide some knobs and pull some levers. The example in the lecture uses the same idea for demonstrating the intuition of neural networks.\n\nExercise 5.1\nUsing the dataset with the two point clouds, create the minimal neural network that separates the clusters. You can share your answer with a link (the URL on playground.tensorflow.org changes as you update the network, so at any time you can use the link to show others what you have created).\n\n\nExercise 5.2\nUsing the dataset with the two circular clusters, one inner and one outer. Create the minimal neural network that separates the clusters.\n\n\nExercise 5.3 (OPTIONAL)\nSee if you can create a network that performs well on the the dataset with the intertwined spirals. Can you do it with only \\(x_1\\) and \\(x_2\\)? > Hints: > > Try experimenting with depth of the network, regularization and possibly the activation function\n\nHaving now slid some knobs and pulled some levers to get some intuition for how the neural networks operate, we turn to the Multilayer Perceptron in sklearn.\n\nExercise 5.4 (OPTIONAL)\nTry to create a neural network which performs better than the best model on the test data. You may want to consider looking at different strengths of regularization (alpha, perhaps using np.logspace) and different amounts of hidden layers and hidden neurons. At this point in time, a just semi-exhaustive search of hyperparameters becomes computationally infeasible, and machine learning turns to art.\nNote: It is not given that a neural network performs best for the given problem, and even if the model exists, it may be hard to find the right architecture. I have not succeeded.\n\nHints:\nIt may be time-consuming to do k fold cross validation. Splitting your development data into a train and validation set a single time is also a possibility. Only rule is that you don’t use the test data for model selection!"
  }
]